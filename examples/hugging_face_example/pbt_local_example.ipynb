{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization with Population-based Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we will use Population-based training (PBT) to optimize the learning rate and weight decay for fine-tuning our classifier based on SageMakerTune.\n",
    "\n",
    "**Note**: This notebook runs all training jobs locally. In order for it to work smoothly, you need to:\n",
    "\n",
    "* Run on a instance with (at least) 4 GPUs, such as for example *ml.g4dn.12xlarge*\n",
    "* Pick a kernel with PyTorch installed, such as for example *conda_pytorch_p36*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install SageMakerTune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to install SagemakerTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sagemakertune\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (21.3)\n",
      "Obtaining file:///home/ec2-user/SageMaker/sagemakertune\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.16.43)\n",
      "Requirement already satisfied: sagemaker>=2.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (2.59.3)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (0.3.4)\n",
      "Requirement already satisfied: PyYaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (5.4.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.1.5)\n",
      "Requirement already satisfied: ujson in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (4.0.2)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (3.10.0.0)\n",
      "Requirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (6.2.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.5.3)\n",
      "Requirement already satisfied: autograd in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (2.25.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (20.9)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (4.5.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (3.17.2)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (1.0.1)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (0.2.8)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (21.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (0.1.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->sagemaker-tune==0.1) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->sagemaker-tune==0.1) (0.3.7)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.43 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->sagemaker-tune==0.1) (1.19.52)\n",
      "Requirement already satisfied: future>=0.15.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from autograd->sagemaker-tune==0.1) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker-tune==0.1) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->sagemaker-tune==0.1) (2021.1)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (1.10.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (0.10.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (2021.5.30)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker>=2.32.0->sagemaker-tune==0.1) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker>=2.32.0->sagemaker-tune==0.1) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker>=2.32.0->sagemaker-tune==0.1) (1.16.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.32.0->sagemaker-tune==0.1) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.32.0->sagemaker-tune==0.1) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.32.0->sagemaker-tune==0.1) (1.6.6.4)\n",
      "Installing collected packages: sagemaker-tune\n",
      "  Attempting uninstall: sagemaker-tune\n",
      "    Found existing installation: sagemaker-tune 0.1\n",
      "    Uninstalling sagemaker-tune-0.1:\n",
      "      Successfully uninstalled sagemaker-tune-0.1\n",
      "  Running setup.py develop for sagemaker-tune\n",
      "Successfully installed sagemaker-tune-0.1\n",
      "/home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/sagemakertune/\n",
    "! pip install --upgrade pip\n",
    "! pip install -e .[gpsearchers]\n",
    "%cd examples/hugging_face_example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.6.1)\n",
      "Requirement already satisfied: datasets[s3]==1.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.6.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.10.3)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.8)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.0.8)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (4.49.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (4.5.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (3.0.12)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==4.6.1) (20.9)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (2021.4.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (5.0.0)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (0.70.12.2)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (0.3.4)\n",
      "Requirement already satisfied: boto3==1.16.43 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (1.16.43)\n",
      "Requirement already satisfied: botocore==1.19.52 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (1.19.52)\n",
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (2021.4.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.3.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (2.8.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==4.6.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==4.6.1) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==4.6.1) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.1) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.1) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->transformers==4.6.1) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets[s3]==1.6.2) (2021.1)\n",
      "Requirement already satisfied: aiobotocore>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from s3fs->datasets[s3]==1.6.2) (1.2.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.1) (1.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.1) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.1) (8.0.1)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.12.1)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (0.7.1)\n",
      "Requirement already satisfied: aiohttp>=3.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (3.7.4.post0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (3.0.1)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers==4.6.1\" \"datasets[s3]==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the maximum number of parallel workers to evaluate hyperparameter configurations. Training jobs of different\n",
    "# workers are executed as subprocesses (we are using the \"local\" back-end). This means you should choose the number of\n",
    "# workers to be no larger than the number of GPUs on the instance.\n",
    "# If you like to use more workers or run on smaller GPU instances, you should use the \"sagemaker\" back-end, which\n",
    "# however comes with larger overheads for starting and stopping a training job.\n",
    "n_workers = 4\n",
    "\n",
    "# The size of the population that PBT maintains\n",
    "population_size = 8\n",
    "\n",
    "# Specifies whether we maximize or minimize our metric\n",
    "mode = 'max'\n",
    "\n",
    "# The metric we aim to optimize. Needs to match the key name reported in your training script\n",
    "metric = 'accuracy'\n",
    "\n",
    "# PBT assignes more resources to better performing models. This parameters defines the resources that we want to use\n",
    "resource_attr = 'iteration'\n",
    "\n",
    "# The maximum amount of resources we can assign to any model.\n",
    "max_iterations = 73 # corresponds to 3 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Configuration Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the domain for each hyperparameter we want to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_tune.search_space import loguniform\n",
    "\n",
    "config_space = {\n",
    "    'learning_rate': loguniform(1e-6, 1e-4),\n",
    "    'weight_decay': loguniform(1e-6, 1e-4)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have additional arguments that we want pass to our train function, we can add them to the config space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_space['model_name'] = 'distilbert-base-uncased'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hugging Face SageMaker Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use SagemakerTune we need to modify our train function slightly. First we will add an additional\n",
    "command line argument to specify the hyperparameters. Additionally we will add an argument that specifies where we will store the checkpoints. This will parameter will be automatically set by SagemakerTune and allows is to start the evaluation of a configuration from a previous configuration\n",
    "\n",
    "\n",
    "```\n",
    "from sagemaker_tune.constants import SMT_CHECKPOINT_DIR\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--epochs\", type=int, default=3)\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=500)\n",
    "    parser.add_argument(\"--model_name\", type=str)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=5e-5)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=5e-5)\n",
    "    parser.add_argument(\"--eval_steps\", type=int, default=32)\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default='./output')\n",
    "\n",
    "    parser.add_argument(f\"--{SMT_CHECKPOINT_DIR}\", type=str)\n",
    "\n",
    "```\n",
    "\n",
    "Next we need to report the performance of the current model back to SageMakerTune. For that we will\n",
    "add a callback function, which reports results back to SageMaker Tune after each evaluation:\n",
    "\n",
    "```\n",
    "    from sagemaker_tune.report import Reporter\n",
    "\n",
    "    report = Reporter()\n",
    "\n",
    "    class Callback(TrainerCallback):\n",
    "        def __init__(self):\n",
    "            self.iteration = 1\n",
    "\n",
    "        def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "            # Feed the validation accuracy back to Tune\n",
    "            report(iteration=self.iteration, accuracy=metrics['eval_accuracy'])\n",
    "            self.iteration += 1\n",
    "\n",
    "\n",
    "    trainer.add_callback(Callback())\n",
    "```    \n",
    "\n",
    "Lastly, we need to make sure that if SageMakerTune provides us with a checkpoint, we start the evaluation from there:\n",
    "\n",
    "``` \n",
    "    if os.listdir(checkpoint_dir) == []:\n",
    "        trainer.train()\n",
    "    else:\n",
    "        trainer.train(resume_from_checkpoint=os.path.join(checkpoint_dir, os.listdir(checkpoint_dir)[0]))\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import sagemaker_tune\n",
    "\n",
    "p = Path.cwd()\n",
    "training_script = str(p) +  '/scripts/train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the LocalBackend which distributed the HPO on the local machine. Alternatively, we can also use the SageMakerBackend where each trial, i.e function evaluation will be executed on a Sagemaker instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_tune.backend.local_backend import LocalBackend\n",
    "    \n",
    "backend = LocalBackend(entry_point=training_script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining PBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.utils.default_arguments:scheduler_options: Key 'searcher': Imputing default value random\n",
      "scheduler_options: Key 'resume': Imputing default value False\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.fifo:Master random_seed = 1979086150\n"
     ]
    }
   ],
   "source": [
    "from sagemaker_tune.optimizer.schedulers.pbt import PopulationBasedTraining\n",
    "\n",
    "scheduler =  PopulationBasedTraining(config_space=config_space,\n",
    "                                  metric=metric,\n",
    "                                  resource_attr=resource_attr,\n",
    "                                  population_size=population_size,\n",
    "                                  mode=mode,\n",
    "                                  max_t=max_iterations,\n",
    "                                  perturbation_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker_tune.tuner:results of trials will be saved on /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[0: random]\n",
      "learning_rate: 1.0000000000000016e-05\n",
      "weight_decay: 1.0000000000000016e-05\n",
      "INFO:root:Detected 4 GPUs\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 1.0000000000000016e-05 --weight_decay 1.0000000000000016e-05 --model_name distilbert-base-uncased --trial_id 0 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/0/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 0) - scheduled config {'learning_rate': 1.0000000000000016e-05, 'weight_decay': 1.0000000000000016e-05, 'model_name': 'distilbert-base-uncased', 'trial_id': '0'}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[1: random]\n",
      "learning_rate: 3.3375351336962146e-06\n",
      "weight_decay: 5.838882957751818e-06\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 3.3375351336962146e-06 --weight_decay 5.838882957751818e-06 --model_name distilbert-base-uncased --trial_id 1 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/1/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 1) - scheduled config {'learning_rate': 3.3375351336962146e-06, 'weight_decay': 5.838882957751818e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': '1'}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[2: random]\n",
      "learning_rate: 4.512668814373329e-05\n",
      "weight_decay: 1.7652850024010814e-06\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 4.512668814373329e-05 --weight_decay 1.7652850024010814e-06 --model_name distilbert-base-uncased --trial_id 2 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/2/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 2) - scheduled config {'learning_rate': 4.512668814373329e-05, 'weight_decay': 1.7652850024010814e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': '2'}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[3: random]\n",
      "learning_rate: 6.049058641421135e-05\n",
      "weight_decay: 8.647335696131798e-06\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 6.049058641421135e-05 --weight_decay 8.647335696131798e-06 --model_name distilbert-base-uncased --trial_id 3 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/3/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 3) - scheduled config {'learning_rate': 6.049058641421135e-05, 'weight_decay': 8.647335696131798e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': '3'}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 35.13s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 70.17s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 105.22s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 140.26s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 175.30s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 210.34s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 245.39s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 280.43s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 315.47s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 350.51s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 385.56s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 420.60s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 455.64s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 490.69s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased\n",
      "       1  InProgress     0       0.000003      0.000006  distilbert-base-uncased\n",
      "       2  InProgress     0       0.000045      0.000002  distilbert-base-uncased\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased\n",
      "4 trials running, 0 finished (0 until the end), 525.73s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     0       0.000010      0.000010  distilbert-base-uncased          -         -            -\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased        1.0   0.49992        501.0\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased        1.0   0.51872        501.0\n",
      "       3  InProgress     0       0.000060      0.000009  distilbert-base-uncased          -         -            -\n",
      "4 trials running, 0 finished (0 until the end), 560.95s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 596.01s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 631.06s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 666.10s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 701.15s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 736.20s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 771.25s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 806.29s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 841.34s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 876.39s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 911.44s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 946.48s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 981.53s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     1       0.000003      0.000006  distilbert-base-uncased          1   0.49992          501\n",
      "       2  InProgress     1       0.000045      0.000002  distilbert-base-uncased          1   0.51872          501\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 1016.57s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased          2   0.50376          978\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased          2   0.55764          978\n",
      "       3  InProgress     1       0.000060      0.000009  distilbert-base-uncased          1   0.55032          531\n",
      "4 trials running, 0 finished (0 until the end), 1051.62s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time\n",
      "       0  InProgress     1       0.000010      0.000010  distilbert-base-uncased          1   0.50004          538\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased          2   0.50376          978\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased          2   0.55764          978\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased          2   0.79468         1031\n",
      "4 trials running, 0 finished (0 until the end), 1086.68s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 4.839246913136908e-05 --weight_decay 1.0376802835358157e-05 --model_name distilbert-base-uncased --trial_id 4 --elapsed_time 1086.6832325458527 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/4/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 4) - scheduled config {'learning_rate': 4.839246913136908e-05, 'weight_decay': 1.0376802835358157e-05, 'model_name': 'distilbert-base-uncased', 'trial_id': 4, 'elapsed_time': 1086.6832325458527} using from trial's checkpoint 3\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1122.34s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1157.38s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1192.43s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1227.47s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1262.52s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1297.57s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1332.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1367.66s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1402.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1437.75s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1472.80s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     2       0.000003      0.000006  distilbert-base-uncased        2.0   0.50376        978.0             -\n",
      "       2  InProgress     2       0.000045      0.000002  distilbert-base-uncased        2.0   0.55764        978.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "5 trials running, 0 finished (0 until the end), 1507.84s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 3.610135051498663e-05 --weight_decay 9.328429781720176e-06 --model_name distilbert-base-uncased --trial_id 5 --elapsed_time 1517.8605782985687 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/5/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 5) - scheduled config {'learning_rate': 3.610135051498663e-05, 'weight_decay': 9.328429781720176e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 5, 'elapsed_time': 1517.8605782985687} using from trial's checkpoint 2\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1543.49s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1578.54s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     2       0.000060      0.000009  distilbert-base-uncased        2.0   0.79468       1031.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1613.59s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     0       0.000048      0.000010  distilbert-base-uncased          -         -            -   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1648.68s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1683.73s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1718.78s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1753.82s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1788.87s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1823.92s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1858.96s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1894.01s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1929.06s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     3       0.000045      0.000002  distilbert-base-uncased        3.0   0.80796       1477.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1964.10s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased        4.0   0.86848       1947.0             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased        3.0   0.86580       1569.0             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased        1.0   0.86580        548.0   1086.683233\n",
      "       5  InProgress     0       0.000036      0.000009  distilbert-base-uncased          -         -            -   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 1999.16s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased          3   0.86580         1569             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased          1   0.86580          548   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2034.21s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     3       0.000060      0.000009  distilbert-base-uncased          3   0.86580         1569             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased          1   0.86580          548   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2069.25s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     1       0.000048      0.000010  distilbert-base-uncased          1   0.86580          548   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2104.32s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2139.37s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2174.42s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2209.46s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2244.51s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2279.55s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2314.60s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2349.65s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2384.69s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2419.73s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     4       0.000045      0.000002  distilbert-base-uncased          4   0.86848         1947             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     1       0.000036      0.000009  distilbert-base-uncased          1   0.86848          468   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2454.78s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2489.85s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2524.88s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2559.92s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     4       0.000060      0.000009  distilbert-base-uncased          4   0.88356         2046             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2594.96s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     2       0.000048      0.000010  distilbert-base-uncased          2   0.88356         1027   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2630.00s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2665.04s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2700.07s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2735.10s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2770.14s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2805.18s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2840.22s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2875.27s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     5       0.000045      0.000002  distilbert-base-uncased          5   0.87788         2422             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2910.32s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     2       0.000036      0.000009  distilbert-base-uncased          2   0.87788          942   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2945.37s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 2980.43s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3015.48s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3050.52s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     5       0.000060      0.000009  distilbert-base-uncased          5   0.88964         2555             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3085.57s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3120.63s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     3       0.000048      0.000010  distilbert-base-uncased          3   0.88964         1543   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3155.68s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3190.73s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3225.78s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3260.82s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3295.87s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3330.92s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3365.97s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3401.01s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     6       0.000045      0.000002  distilbert-base-uncased          6   0.88892         2892             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     3       0.000036      0.000009  distilbert-base-uncased          3   0.88892         1411   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3436.06s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3471.13s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3506.18s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3541.22s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3576.27s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     6       0.000060      0.000009  distilbert-base-uncased          6   0.89472         3054             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3611.31s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3646.37s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3681.41s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     4       0.000048      0.000010  distilbert-base-uncased          4   0.89472         2058   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3716.46s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased          5   0.90672         2606   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3751.52s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased          5   0.90672         2606   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3786.56s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased          5   0.90672         2606   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3821.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased          5   0.90672         2606   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3856.66s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     7       0.000045      0.000002  distilbert-base-uncased          7   0.90780         3392             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased          7   0.90672         3592             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased          5   0.90672         2606   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased          4   0.90780         1910   1517.860578\n",
      "6 trials running, 0 finished (0 until the end), 3891.70s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 2.8881080411989306e-05 --weight_decay 1.1194115738064211e-05 --model_name distilbert-base-uncased --trial_id 6 --elapsed_time 3921.739371776581 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/6/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 6) - scheduled config {'learning_rate': 2.8881080411989306e-05, 'weight_decay': 1.1194115738064211e-05, 'model_name': 'distilbert-base-uncased', 'trial_id': 6, 'elapsed_time': 3921.739371776581} using from trial's checkpoint 5\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased        7.0   0.90672       3592.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     4       0.000036      0.000009  distilbert-base-uncased        4.0   0.90780       1910.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "7 trials running, 0 finished (0 until the end), 3927.36s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 3.8713975305095264e-05 --weight_decay 8.301442268286527e-06 --model_name distilbert-base-uncased --trial_id 7 --elapsed_time 3932.371546983719 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/7/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 7) - scheduled config {'learning_rate': 3.8713975305095264e-05, 'weight_decay': 8.301442268286527e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 7, 'elapsed_time': 3932.371546983719} using from trial's checkpoint 4\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased        7.0   0.90672       3592.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "8 trials running, 0 finished (0 until the end), 3963.21s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased        7.0   0.90672       3592.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "8 trials running, 0 finished (0 until the end), 3998.26s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased        7.0   0.90672       3592.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "8 trials running, 0 finished (0 until the end), 4033.30s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased        7.0   0.90672       3592.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "8 trials running, 0 finished (0 until the end), 4068.35s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     7       0.000060      0.000009  distilbert-base-uncased        7.0   0.90672       3592.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "8 trials running, 0 finished (0 until the end), 4103.39s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 3.8713975305095264e-05 --weight_decay 2.2738315141819544e-06 --model_name distilbert-base-uncased --trial_id 8 --elapsed_time 4113.4100177288055 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/8/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 8) - scheduled config {'learning_rate': 3.8713975305095264e-05, 'weight_decay': 2.2738315141819544e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 8, 'elapsed_time': 4113.4100177288055} using from trial's checkpoint 4\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4139.07s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     5       0.000048      0.000010  distilbert-base-uncased        5.0   0.90672       2606.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4174.12s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4209.18s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4244.22s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4279.27s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4314.31s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4349.36s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     0       0.000029      0.000011  distilbert-base-uncased          -         -            -   3921.739372\n",
      "       7  InProgress     0       0.000039      0.000008  distilbert-base-uncased          -         -            -   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4384.41s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased        1.0   0.90608        462.0   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased        1.0   0.88748        459.0   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4419.46s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased        1.0   0.90608        462.0   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased        1.0   0.88748        459.0   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4454.51s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased        1.0   0.90608        462.0   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased        1.0   0.88748        459.0   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4489.56s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased        1.0   0.90608        462.0   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased        1.0   0.88748        459.0   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4524.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased        1.0   0.90608        462.0   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased        1.0   0.88748        459.0   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4559.65s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased        6.0   0.90672       3080.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased        1.0   0.90608        462.0   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased        1.0   0.88748        459.0   3932.371547\n",
      "       8  InProgress     0       0.000039      0.000002  distilbert-base-uncased          -         -            -   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4594.70s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased          6   0.90672         3080   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4629.76s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     6       0.000048      0.000010  distilbert-base-uncased          6   0.90672         3080   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4664.81s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4699.88s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4734.92s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4769.97s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4805.02s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4840.06s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     1       0.000029      0.000011  distilbert-base-uncased          1   0.90608          462   3921.739372\n",
      "       7  InProgress     1       0.000039      0.000008  distilbert-base-uncased          1   0.88748          459   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4875.11s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4910.17s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4945.21s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 4980.26s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5015.31s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5050.35s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5085.40s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     1       0.000039      0.000002  distilbert-base-uncased          1   0.88748          477   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5120.44s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5155.50s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     7       0.000048      0.000010  distilbert-base-uncased          7   0.91208         3563   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5190.55s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased          8   0.91208         4105   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5225.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased          8   0.91208         4105   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5260.65s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased          8   0.91208         4105   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5295.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased          8   0.91208         4105   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5330.76s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased          8   0.91208         4105   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     2       0.000029      0.000011  distilbert-base-uncased          2   0.90904          937   3921.739372\n",
      "       7  InProgress     2       0.000039      0.000008  distilbert-base-uncased          2   0.91208          934   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased          2   0.91208         1006   4113.410018\n",
      "9 trials running, 0 finished (0 until the end), 5365.80s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 3.0971180244076214e-05 --weight_decay 2.728597817018345e-06 --model_name distilbert-base-uncased --trial_id 9 --elapsed_time 5370.814773321152 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/9/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 9) - scheduled config {'learning_rate': 3.0971180244076214e-05, 'weight_decay': 2.728597817018345e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 9, 'elapsed_time': 5370.814773321152} using from trial's checkpoint 8\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5401.47s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5436.51s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5471.55s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5506.60s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5541.65s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5576.70s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     2       0.000039      0.000002  distilbert-base-uncased        2.0   0.91208       1006.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5611.74s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5646.80s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5681.84s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     8       0.000048      0.000010  distilbert-base-uncased        8.0   0.91208       4105.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "10 trials running, 0 finished (0 until the end), 5716.90s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 8.600915593711971e-05 --weight_decay 2.728597817018345e-06 --model_name distilbert-base-uncased --trial_id 10 --elapsed_time 5716.90468454361 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/10/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 10) - scheduled config {'learning_rate': 8.600915593711971e-05, 'weight_decay': 2.728597817018345e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 10, 'elapsed_time': 5716.90468454361} using from trial's checkpoint 8\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "11 trials running, 0 finished (0 until the end), 5752.56s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "11 trials running, 0 finished (0 until the end), 5787.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "11 trials running, 0 finished (0 until the end), 5822.66s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     3       0.000039      0.000008  distilbert-base-uncased        3.0   0.91208       1424.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "11 trials running, 0 finished (0 until the end), 5857.71s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 3.0971180244076214e-05 --weight_decay 2.728597817018345e-06 --model_name distilbert-base-uncased --trial_id 11 --elapsed_time 5862.722927570343 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/11/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 11) - scheduled config {'learning_rate': 3.0971180244076214e-05, 'weight_decay': 2.728597817018345e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 11, 'elapsed_time': 5862.722927570343} using from trial's checkpoint 8\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 5893.39s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 5928.44s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 5963.49s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 5998.53s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 6033.58s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 6068.62s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 6103.67s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 6138.72s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     3       0.000039      0.000002  distilbert-base-uncased        3.0   0.91208       1502.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "12 trials running, 0 finished (0 until the end), 6173.77s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 2.0612150249741643e-06 --weight_decay 2.1828782536146762e-06 --model_name distilbert-base-uncased --trial_id 12 --elapsed_time 6178.779193878174 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/12/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 12) - scheduled config {'learning_rate': 2.0612150249741643e-06, 'weight_decay': 2.1828782536146762e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 12, 'elapsed_time': 6178.779193878174} using from trial's checkpoint 9\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "13 trials running, 0 finished (0 until the end), 6209.42s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     0       0.000086      0.000003  distilbert-base-uncased          -         -            -   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "13 trials running, 0 finished (0 until the end), 6244.47s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 1.3927475679953013e-06 --weight_decay 3.274317380422014e-06 --model_name distilbert-base-uncased --trial_id 13 --elapsed_time 6274.50515294075 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/13/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 13) - scheduled config {'learning_rate': 1.3927475679953013e-06, 'weight_decay': 3.274317380422014e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 13, 'elapsed_time': 6274.50515294075} using from trial's checkpoint 9\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6280.15s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6315.19s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.91208        493.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     0       0.000031      0.000003  distilbert-base-uncased          -         -            -   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6350.24s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6385.30s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6420.33s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6455.38s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6490.43s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6525.48s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6560.53s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6595.58s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6630.62s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6665.66s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6700.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6735.77s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6770.82s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.91208        974.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased        1.0   0.90744        483.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     0       0.000001      0.000003  distilbert-base-uncased          -         -            -   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6805.87s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.91208          974   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     1       0.000031      0.000003  distilbert-base-uncased          1   0.90744          483   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.90744          506   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased          1   0.90744          525   6274.505153\n",
      "14 trials running, 0 finished (0 until the end), 6840.93s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 1.1141980543962412e-06 --weight_decay 3.579477051587788e-05 --model_name distilbert-base-uncased --trial_id 14 --elapsed_time 6855.954411506653 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/14/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 14) - scheduled config {'learning_rate': 1.1141980543962412e-06, 'weight_decay': 3.579477051587788e-05, 'model_name': 'distilbert-base-uncased', 'trial_id': 14, 'elapsed_time': 6855.954411506653} using from trial's checkpoint 13\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 1.6712970815943614e-06 --weight_decay 3.929180856506417e-06 --model_name distilbert-base-uncased --trial_id 15 --elapsed_time 6861.601147651672 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/15/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 15) - scheduled config {'learning_rate': 1.6712970815943614e-06, 'weight_decay': 3.929180856506417e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 15, 'elapsed_time': 6861.601147651672} using from trial's checkpoint 13\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 6872.56s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 6907.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 6942.66s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 6977.72s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7012.77s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7047.83s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7082.88s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7117.94s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7152.99s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7188.05s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.90744        506.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "16 trials running, 0 finished (0 until the end), 7223.10s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 1.6712970815943614e-06 --weight_decay 2.6194539043376114e-06 --model_name distilbert-base-uncased --trial_id 16 --elapsed_time 7238.132998943329 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/16/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 16) - scheduled config {'learning_rate': 1.6712970815943614e-06, 'weight_decay': 2.6194539043376114e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 16, 'elapsed_time': 7238.132998943329} using from trial's checkpoint 13\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7258.79s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7293.84s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7328.88s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     1       0.000001      0.000003  distilbert-base-uncased        1.0   0.90744        525.0   6274.505153\n",
      "      14  InProgress     0       0.000001      0.000036  distilbert-base-uncased          -         -            -   6855.954412\n",
      "      15  InProgress     0       0.000002      0.000004  distilbert-base-uncased          -         -            -   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7363.93s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7399.00s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7434.05s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7469.09s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7504.14s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7539.19s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7574.23s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7609.28s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7644.32s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7679.37s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7714.41s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7749.46s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased        2.0   0.90744       1072.0   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased        1.0   0.87068        507.0   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased        1.0   0.87068        509.0   6861.601148\n",
      "      16  InProgress     0       0.000002      0.000003  distilbert-base-uncased          -         -            -   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7784.50s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased          2   0.90744         1072   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased          1   0.87068          507   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased          1   0.87068          509   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7819.56s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased          2   0.90744         1072   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased          1   0.87068          507   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased          1   0.87068          509   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7854.60s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     2       0.000001      0.000003  distilbert-base-uncased          2   0.90744         1072   6274.505153\n",
      "      14  InProgress     1       0.000001      0.000036  distilbert-base-uncased          1   0.87068          507   6855.954412\n",
      "      15  InProgress     1       0.000002      0.000004  distilbert-base-uncased          1   0.87068          509   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7889.65s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7924.74s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7959.80s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 7994.84s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8029.89s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8064.94s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8099.99s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8135.03s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8170.08s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8205.12s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8240.17s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8275.22s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     1       0.000002      0.000003  distilbert-base-uncased          1   0.87068          537   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8310.26s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased          2   0.89244         1071   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8345.32s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased          3   0.90744         1617   6274.505153\n",
      "      14  InProgress     2       0.000001      0.000036  distilbert-base-uncased          2   0.89244         1011   6855.954412\n",
      "      15  InProgress     2       0.000002      0.000004  distilbert-base-uncased          2   0.89244         1014   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased          2   0.89244         1071   7238.132999\n",
      "17 trials running, 0 finished (0 until the end), 8380.37s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 2.636190777007463e-05 --weight_decay 3.1433446852051334e-06 --model_name distilbert-base-uncased --trial_id 17 --elapsed_time 8395.395519733429 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/17/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 17) - scheduled config {'learning_rate': 2.636190777007463e-05, 'weight_decay': 3.1433446852051334e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 17, 'elapsed_time': 8395.395519733429} using from trial's checkpoint 16\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 2.0055564979132336e-06 --weight_decay 2.0955631234700894e-06 --model_name distilbert-base-uncased --trial_id 18 --elapsed_time 8406.00965476036 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/18/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 18) - scheduled config {'learning_rate': 2.0055564979132336e-06, 'weight_decay': 2.0955631234700894e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 18, 'elapsed_time': 8406.00965476036} using from trial's checkpoint 16\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased        3.0   0.90744       1617.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "19 trials running, 0 finished (0 until the end), 8411.91s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     3       0.000001      0.000003  distilbert-base-uncased        3.0   0.90744       1617.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "19 trials running, 0 finished (0 until the end), 8446.96s wallclock-time\n",
      "\n",
      "INFO:root:running subprocess with command: python /home/ec2-user/SageMaker/sagemakertune/examples/hugging_face_example/scripts/train.py --learning_rate 1.3370376652754892e-06 --weight_decay 2.0955631234700894e-06 --model_name distilbert-base-uncased --trial_id 19 --elapsed_time 8461.984364271164 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/train-2021-10-18-10-28-35-781/19/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 19) - scheduled config {'learning_rate': 1.3370376652754892e-06, 'weight_decay': 2.0955631234700894e-06, 'model_name': 'distilbert-base-uncased', 'trial_id': 19, 'elapsed_time': 8461.984364271164} using from trial's checkpoint 16\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8482.62s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8517.66s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8552.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8587.75s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8622.81s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8657.86s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8692.91s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8727.95s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8763.00s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8798.05s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     2       0.000002      0.000003  distilbert-base-uncased        2.0   0.89244       1071.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8833.09s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased        3.0   0.89244       1604.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8868.15s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased        3.0   0.89244       1604.0   7238.132999\n",
      "      17  InProgress     0       0.000026      0.000003  distilbert-base-uncased          -         -            -   8395.395520\n",
      "      18  InProgress     0       0.000002      0.000002  distilbert-base-uncased          -         -            -   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8903.20s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased        3.0   0.89244       1604.0   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased        1.0   0.85652        505.0   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.85652        503.0   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8938.27s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased        3.0   0.89244       1604.0   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased        1.0   0.85652        505.0   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.85652        503.0   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 8973.31s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased        2.0   0.50040       1044.0             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased        3.0   0.51324       1477.0             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased        8.0   0.90780       3877.0             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased        8.0   0.90672       4073.0             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased        9.0   0.91208       4608.0   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased        5.0   0.90780       2393.0   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased        3.0   0.90920       1429.0   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased        4.0   0.91208       1908.0   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased        4.0   0.91208       2041.0   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased        3.0   0.91208       1467.0   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased        1.0   0.90744        535.0   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased        2.0   0.90744        975.0   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased        2.0   0.90744       1037.0   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased        4.0   0.90744       2168.0   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased        3.0   0.89244       1517.0   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased        3.0   0.89244       1522.0   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased        3.0   0.89244       1604.0   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased        1.0   0.85652        505.0   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased        1.0   0.85652        503.0   8406.009655\n",
      "      19  InProgress     0       0.000001      0.000002  distilbert-base-uncased          -         -            -   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9008.36s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9043.43s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9078.47s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9113.52s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9148.57s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9183.62s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9218.67s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9253.72s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9288.77s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9323.82s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     3       0.000002      0.000003  distilbert-base-uncased          3   0.89244         1604   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9358.86s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     1       0.000026      0.000003  distilbert-base-uncased          1   0.85652          505   8395.395520\n",
      "      18  InProgress     1       0.000002      0.000002  distilbert-base-uncased          1   0.85652          503   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9393.93s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9428.99s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9464.04s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9499.09s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     1       0.000001      0.000002  distilbert-base-uncased          1   0.85652          527   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9534.14s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9569.20s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9604.25s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9639.29s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9674.35s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9709.39s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9744.44s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9779.49s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "trial_id      status  iter  learning_rate  weight_decay               model_name  iteration  accuracy  worker-time  elapsed_time\n",
      "       0  InProgress     2       0.000010      0.000010  distilbert-base-uncased          2   0.50040         1044             -\n",
      "       1  InProgress     3       0.000003      0.000006  distilbert-base-uncased          3   0.51324         1477             -\n",
      "       2  InProgress     8       0.000045      0.000002  distilbert-base-uncased          8   0.90780         3877             -\n",
      "       3  InProgress     8       0.000060      0.000009  distilbert-base-uncased          8   0.90672         4073             -\n",
      "       4  InProgress     9       0.000048      0.000010  distilbert-base-uncased          9   0.91208         4608   1086.683233\n",
      "       5  InProgress     5       0.000036      0.000009  distilbert-base-uncased          5   0.90780         2393   1517.860578\n",
      "       6  InProgress     3       0.000029      0.000011  distilbert-base-uncased          3   0.90920         1429   3921.739372\n",
      "       7  InProgress     4       0.000039      0.000008  distilbert-base-uncased          4   0.91208         1908   3932.371547\n",
      "       8  InProgress     4       0.000039      0.000002  distilbert-base-uncased          4   0.91208         2041   4113.410018\n",
      "       9  InProgress     3       0.000031      0.000003  distilbert-base-uncased          3   0.91208         1467   5370.814773\n",
      "      10  InProgress     1       0.000086      0.000003  distilbert-base-uncased          1   0.90744          535   5716.904685\n",
      "      11  InProgress     2       0.000031      0.000003  distilbert-base-uncased          2   0.90744          975   5862.722928\n",
      "      12  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.90744         1037   6178.779194\n",
      "      13  InProgress     4       0.000001      0.000003  distilbert-base-uncased          4   0.90744         2168   6274.505153\n",
      "      14  InProgress     3       0.000001      0.000036  distilbert-base-uncased          3   0.89244         1517   6855.954412\n",
      "      15  InProgress     3       0.000002      0.000004  distilbert-base-uncased          3   0.89244         1522   6861.601148\n",
      "      16  InProgress     4       0.000002      0.000003  distilbert-base-uncased          4   0.89244         2100   7238.132999\n",
      "      17  InProgress     2       0.000026      0.000003  distilbert-base-uncased          2   0.88188          981   8395.395520\n",
      "      18  InProgress     2       0.000002      0.000002  distilbert-base-uncased          2   0.88188          983   8406.009655\n",
      "      19  InProgress     2       0.000001      0.000002  distilbert-base-uncased          2   0.88188         1052   8461.984364\n",
      "20 trials running, 0 finished (0 until the end), 9814.54s wallclock-time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker_tune.tuner import Tuner\n",
    "from sagemaker_tune.stopping_criterion import StoppingCriterion\n",
    "from sagemaker_tune.remote.remote_launcher import RemoteLauncher\n",
    "\n",
    "stop_criterion = StoppingCriterion(max_wallclock_time=10800)\n",
    "tuner = Tuner(\n",
    "    backend=backend,\n",
    "    scheduler=scheduler,\n",
    "    stop_criterion=stop_criterion,\n",
    "    n_workers=n_workers,\n",
    ")\n",
    "\n",
    "results = tuner.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows the optimization process of PBT. Each dot represents the performance of \n",
    "the current model and the color indicates the same hyperparameter configuration. The solid blue line represents the \n",
    "performance of the best model found so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.95)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sagemaker_tune.experiments import load_experiment\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "r = load_experiment(tuner.tuner_path)\n",
    "df = r.results\n",
    "plt.plot(df['smt_tuner_time'], df['accuracy'].cummax(), linewidth=4)\n",
    "\n",
    "for trial_id in df.trial_id.unique():\n",
    "    sub_df = df[df['trial_id'] == trial_id]\n",
    "    y = sub_df['accuracy'].cummax()\n",
    "    rt =sub_df['smt_tuner_time']    \n",
    "    plt.plot(rt, y, marker='o', alpha=0.4)\n",
    "\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('wall-clock time (seconds)')\n",
    "plt.ylim(0.8, 0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
