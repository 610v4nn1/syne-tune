{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6b08f8",
   "metadata": {},
   "source": [
    "# SageMaker Tune in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08d06f",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to tune hyperparameters with Sagemaker Tune. In particular, we will show how to tune the hyperparameters of a computer-vision model on a local machine and then on SageMaker with many more machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747367c6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b5d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sagemaker-tune\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/sagemaker-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad602c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary note need ssh key since the repo is private or manual upload.\n",
    "!git clone git@github.com:awslabs/sagemaker-tune.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29e0198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout blog-post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b25c2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 11, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (11/11), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (1/1), done.\u001B[K\r\n",
      "remote: Total 6 (delta 3), reused 6 (delta 3), pack-reused 0\u001B[K\r\n",
      "Unpacking objects: 100% (6/6), done.\r\n",
      "From github.com:awslabs/sagemaker-tune\r\n",
      "   d424cf2..c5d7c83  blog       -> origin/blog\r\n",
      "Updating d424cf2..c5d7c83\r\n",
      "Fast-forward\r\n",
      " blog-post/pytorch_cnn_cifar10/source/cifar10.py | 8 \u001B[32m++++++++\u001B[m\r\n",
      " 1 file changed, 8 insertions(+)\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6febebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/ec2-user/SageMaker/sagemaker-tune\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.19.3)\n",
      "Requirement already satisfied: sagemaker>=2.32.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (2.66.0)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (0.3.4)\n",
      "Requirement already satisfied: PyYaml in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (5.4.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.1.5)\n",
      "Requirement already satisfied: ujson in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (4.0.2)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (3.10.0.2)\n",
      "Requirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (6.2.2)\n",
      "Collecting ray[tune]\n",
      "  Using cached ray-1.8.0-cp36-cp36m-manylinux2014_x86_64.whl (54.7 MB)\n",
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (0.0)\n",
      "Collecting scikit-optimize\n",
      "  Using cached scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.5.3)\n",
      "Collecting autograd\n",
      "  Using cached autograd-1.3-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (4.62.3)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.3.2-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (1.7.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-tune==0.1) (0.8.2)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (0.1.5)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (21.2.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (4.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (21.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (3.19.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.32.0->sagemaker-tune==0.1) (1.19.5)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3->sagemaker-tune==0.1) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3->sagemaker-tune==0.1) (1.22.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3->sagemaker-tune==0.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3->sagemaker-tune==0.1) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.23.0,>=1.22.3->boto3->sagemaker-tune==0.1) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker>=2.32.0->sagemaker-tune==0.1) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker>=2.32.0->sagemaker-tune==0.1) (3.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker>=2.32.0->sagemaker-tune==0.1) (1.16.0)\n",
      "Requirement already satisfied: future>=0.15.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from autograd->sagemaker-tune==0.1) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker-tune==0.1) (2021.3)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.32.0->sagemaker-tune==0.1) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.32.0->sagemaker-tune==0.1) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.32.0->sagemaker-tune==0.1) (0.70.12.2)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (1.10.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytest->sagemaker-tune==0.1) (0.10.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]->sagemaker-tune==0.1) (7.1.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]->sagemaker-tune==0.1) (1.0.2)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]->sagemaker-tune==0.1) (0.8)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]->sagemaker-tune==0.1) (3.2.0)\n",
      "Collecting redis>=3.5.0\n",
      "  Using cached redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "Collecting grpcio>=1.28.1\n",
      "  Using cached grpcio-1.41.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from ray[tune]->sagemaker-tune==0.1) (0.8.9)\n",
      "Collecting tensorboardX>=1.9\n",
      "  Using cached tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema->ray[tune]->sagemaker-tune==0.1) (58.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from jsonschema->ray[tune]->sagemaker-tune==0.1) (0.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->sagemaker-tune==0.1) (3.3)\n",
      "Collecting pyaml>=16.9\n",
      "  Using cached pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from scikit-optimize->sagemaker-tune==0.1) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from scikit-optimize->sagemaker-tune==0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from scikit-learn>=0.20.0->scikit-optimize->sagemaker-tune==0.1) (2.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from torchvision->sagemaker-tune==0.1) (8.3.2)\n",
      "Installing collected packages: redis, grpcio, filelock, tensorboardX, ray, pyaml, scikit-optimize, sagemaker-tune, autograd\n",
      "  Attempting uninstall: sagemaker-tune\n",
      "    Found existing installation: sagemaker-tune 0.1\n",
      "    Uninstalling sagemaker-tune-0.1:\n",
      "      Successfully uninstalled sagemaker-tune-0.1\n",
      "  Running setup.py develop for sagemaker-tune\n",
      "Successfully installed autograd-1.3 filelock-3.3.2 grpcio-1.41.1 pyaml-21.10.1 ray-1.8.0 redis-3.5.3 sagemaker-tune-0.1 scikit-optimize-0.9.0 tensorboardX-2.4\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cd /home/ec2-user/SageMaker/sagemaker-tune/blog-post/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "628915ef",
   "metadata": {},
   "source": [
    "## How to enable tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c20978",
   "metadata": {},
   "source": [
    "To tune hyperparameters, you will need: \n",
    "* 1) a main script that takes hyperparameters as arguments\n",
    "* 2) to add one line to report results once they are obtained\n",
    "\n",
    "Let us take a look at a simplified example of a script that has learning_rate, dropout_rate as hyperparameters and report accuracy over the training epochs.\n",
    "\n",
    "```python\n",
    "from argparse import ArgumentParser\n",
    "from sagemaker_tune.report import Reporter\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--learning_rate', type=float)\n",
    "    parser.add_argument('--dropout_rate', type=float)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    report = Reporter()\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        # ... train model and get accuracy        \n",
    "        accuracy = compute_accuracy()\n",
    "        \n",
    "        # Feed the score back to Sagemaker Tune.\n",
    "        report(epoch=epoch, accuracy=accuracy)\n",
    "```\n",
    "\n",
    "In our case, we are going to use a slightly more complex case that trains a computer-vision model adapted from Sagemaker examples [[link]](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/pytorch_cnn_cifar10/source/cifar10.py).\n",
    "\n",
    "Let us have a look to the full code of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7ac1769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36margparse\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mjson\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mlogging\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mos\u001B[39;49;00m\r\n",
      "\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mnn\u001B[39;49;00m \u001B[34mas\u001B[39;49;00m \u001B[04m\u001B[36mnn\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mnn\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mfunctional\u001B[39;49;00m \u001B[34mas\u001B[39;49;00m \u001B[04m\u001B[36mF\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mnn\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mparallel\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36moptim\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mutils\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mdata\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorch\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mutils\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mdata\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mdistributed\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorchvision\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorchvision\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mmodels\u001B[39;49;00m\r\n",
      "\u001B[34mimport\u001B[39;49;00m \u001B[04m\u001B[36mtorchvision\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mtransforms\u001B[39;49;00m \u001B[34mas\u001B[39;49;00m \u001B[04m\u001B[36mtransforms\u001B[39;49;00m\r\n",
      "\u001B[34mfrom\u001B[39;49;00m \u001B[04m\u001B[36mtqdm\u001B[39;49;00m \u001B[34mimport\u001B[39;49;00m tqdm\r\n",
      "\u001B[34mfrom\u001B[39;49;00m \u001B[04m\u001B[36msagemaker_tune\u001B[39;49;00m\u001B[04m\u001B[36m.\u001B[39;49;00m\u001B[04m\u001B[36mreport\u001B[39;49;00m \u001B[34mimport\u001B[39;49;00m Reporter\r\n",
      "\r\n",
      "logger = logging.getLogger(\u001B[31m__name__\u001B[39;49;00m)\r\n",
      "logger.setLevel(logging.DEBUG)\r\n",
      "\r\n",
      "classes = (\u001B[33m\"\u001B[39;49;00m\u001B[33mplane\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mcar\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mbird\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mcat\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mdeer\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mdog\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mfrog\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mhorse\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mship\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33mtruck\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "\u001B[37m# https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py#L118\u001B[39;49;00m\r\n",
      "\u001B[34mclass\u001B[39;49;00m \u001B[04m\u001B[32mNet\u001B[39;49;00m(nn.Module):\r\n",
      "    \u001B[34mdef\u001B[39;49;00m \u001B[32m__init__\u001B[39;49;00m(\u001B[36mself\u001B[39;49;00m, dropout_rate: \u001B[36mfloat\u001B[39;49;00m = \u001B[34m0.0\u001B[39;49;00m):\r\n",
      "        \u001B[36msuper\u001B[39;49;00m(Net, \u001B[36mself\u001B[39;49;00m).\u001B[32m__init__\u001B[39;49;00m()\r\n",
      "        \u001B[34massert\u001B[39;49;00m \u001B[34m0\u001B[39;49;00m <= dropout_rate <= \u001B[34m1\u001B[39;49;00m\r\n",
      "        \u001B[36mself\u001B[39;49;00m.conv1 = nn.Conv2d(\u001B[34m3\u001B[39;49;00m, \u001B[34m6\u001B[39;49;00m, \u001B[34m5\u001B[39;49;00m)\r\n",
      "        \u001B[36mself\u001B[39;49;00m.pool = nn.MaxPool2d(\u001B[34m2\u001B[39;49;00m, \u001B[34m2\u001B[39;49;00m)\r\n",
      "        \u001B[36mself\u001B[39;49;00m.conv2 = nn.Conv2d(\u001B[34m6\u001B[39;49;00m, \u001B[34m16\u001B[39;49;00m, \u001B[34m5\u001B[39;49;00m)\r\n",
      "        \u001B[36mself\u001B[39;49;00m.fc1 = nn.Linear(\u001B[34m16\u001B[39;49;00m * \u001B[34m5\u001B[39;49;00m * \u001B[34m5\u001B[39;49;00m, \u001B[34m120\u001B[39;49;00m)\r\n",
      "        \u001B[36mself\u001B[39;49;00m.fc2 = nn.Linear(\u001B[34m120\u001B[39;49;00m, \u001B[34m84\u001B[39;49;00m)\r\n",
      "        \u001B[36mself\u001B[39;49;00m.fc3 = nn.Linear(\u001B[34m84\u001B[39;49;00m, \u001B[34m10\u001B[39;49;00m)\r\n",
      "        \u001B[36mself\u001B[39;49;00m.dropout = nn.Dropout(dropout_rate)\r\n",
      "\r\n",
      "    \u001B[34mdef\u001B[39;49;00m \u001B[32mforward\u001B[39;49;00m(\u001B[36mself\u001B[39;49;00m, x):\r\n",
      "        x = \u001B[36mself\u001B[39;49;00m.pool(F.relu(\u001B[36mself\u001B[39;49;00m.conv1(x)))\r\n",
      "        x = \u001B[36mself\u001B[39;49;00m.pool(F.relu(\u001B[36mself\u001B[39;49;00m.conv2(x)))\r\n",
      "        x = x.view(-\u001B[34m1\u001B[39;49;00m, \u001B[34m16\u001B[39;49;00m * \u001B[34m5\u001B[39;49;00m * \u001B[34m5\u001B[39;49;00m)\r\n",
      "        x = F.relu(\u001B[36mself\u001B[39;49;00m.fc1(x))\r\n",
      "        x = F.relu(\u001B[36mself\u001B[39;49;00m.fc2(x))\r\n",
      "        x = \u001B[36mself\u001B[39;49;00m.dropout(x)\r\n",
      "        x = \u001B[36mself\u001B[39;49;00m.fc3(x)\r\n",
      "        \u001B[34mreturn\u001B[39;49;00m x\r\n",
      "\r\n",
      "\r\n",
      "\u001B[34mdef\u001B[39;49;00m \u001B[32mcompute_accuracy\u001B[39;49;00m(model, data_loader, device):\r\n",
      "    model.eval()\r\n",
      "    correct = \u001B[34m0\u001B[39;49;00m\r\n",
      "    \u001B[34mfor\u001B[39;49;00m inputs, labels \u001B[35min\u001B[39;49;00m tqdm(data_loader):\r\n",
      "        \u001B[34mwith\u001B[39;49;00m torch.no_grad():\r\n",
      "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
      "            prediction = model(inputs)\r\n",
      "            prediction = prediction.max(\u001B[34m1\u001B[39;49;00m)[\u001B[34m1\u001B[39;49;00m]\r\n",
      "            correct += prediction.eq(labels.view_as(prediction)).sum().item()\r\n",
      "    n_valid = \u001B[36mlen\u001B[39;49;00m(data_loader.sampler)\r\n",
      "    percentage_correct = \u001B[34m100.0\u001B[39;49;00m * correct / n_valid\r\n",
      "    \u001B[34mreturn\u001B[39;49;00m percentage_correct / \u001B[34m100\u001B[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001B[34mdef\u001B[39;49;00m \u001B[32m_train\u001B[39;49;00m(args):\r\n",
      "    device = \u001B[33m\"\u001B[39;49;00m\u001B[33mcuda\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m \u001B[34mif\u001B[39;49;00m torch.cuda.is_available() \u001B[34melse\u001B[39;49;00m \u001B[33m\"\u001B[39;49;00m\u001B[33mcpu\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\r\n",
      "    logger.info(\u001B[33m\"\u001B[39;49;00m\u001B[33mDevice Type: \u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m.format(device))\r\n",
      "\r\n",
      "    logger.info(\u001B[33m\"\u001B[39;49;00m\u001B[33mLoading Cifar10 dataset\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\r\n",
      "    transform = transforms.Compose(\r\n",
      "        [transforms.ToTensor(), transforms.Normalize((\u001B[34m0.5\u001B[39;49;00m, \u001B[34m0.5\u001B[39;49;00m, \u001B[34m0.5\u001B[39;49;00m), (\u001B[34m0.5\u001B[39;49;00m, \u001B[34m0.5\u001B[39;49;00m, \u001B[34m0.5\u001B[39;49;00m))]\r\n",
      "    )\r\n",
      "\r\n",
      "    trainset = torchvision.datasets.CIFAR10(\r\n",
      "        root=args.data_dir, train=\u001B[34mTrue\u001B[39;49;00m, download=\u001B[34mFalse\u001B[39;49;00m, transform=transform\r\n",
      "    )\r\n",
      "    n_train = \u001B[36mlen\u001B[39;49;00m(trainset) * \u001B[34m8\u001B[39;49;00m // \u001B[34m10\u001B[39;49;00m\r\n",
      "    n_val = \u001B[36mlen\u001B[39;49;00m(trainset) - n_train\r\n",
      "    train_split, val_split = torch.utils.data.random_split(trainset, [n_train, n_val])\r\n",
      "    train_loader = torch.utils.data.DataLoader(\r\n",
      "        train_split, batch_size=args.batch_size, shuffle=\u001B[34mTrue\u001B[39;49;00m, num_workers=args.workers\r\n",
      "    )\r\n",
      "    val_loader = torch.utils.data.DataLoader(\r\n",
      "        val_split, batch_size=\u001B[34m128\u001B[39;49;00m, shuffle=\u001B[34mTrue\u001B[39;49;00m, num_workers=args.workers\r\n",
      "    )\r\n",
      "\r\n",
      "    logger.info(\u001B[33mf\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\u001B[33mlength training/validation splits: \u001B[39;49;00m\u001B[33m{\u001B[39;49;00m\u001B[36mlen\u001B[39;49;00m(train_split)\u001B[33m}\u001B[39;49;00m\u001B[33m/\u001B[39;49;00m\u001B[33m{\u001B[39;49;00m\u001B[36mlen\u001B[39;49;00m(val_split)\u001B[33m}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\r\n",
      "    logger.info(\u001B[33m\"\u001B[39;49;00m\u001B[33mModel loaded\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\r\n",
      "    model = Net(dropout_rate=args.dropout_rate)\r\n",
      "\r\n",
      "    \u001B[34mif\u001B[39;49;00m torch.cuda.device_count() > \u001B[34m1\u001B[39;49;00m:\r\n",
      "        logger.info(\u001B[33m\"\u001B[39;49;00m\u001B[33mGpu count: \u001B[39;49;00m\u001B[33m{}\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m.format(torch.cuda.device_count()))\r\n",
      "        model = nn.DataParallel(model)\r\n",
      "\r\n",
      "    model = model.to(device)\r\n",
      "\r\n",
      "    criterion = nn.CrossEntropyLoss().to(device)\r\n",
      "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\r\n",
      "\r\n",
      "    reporter = Reporter()\r\n",
      "    \u001B[34mfor\u001B[39;49;00m epoch \u001B[35min\u001B[39;49;00m \u001B[36mrange\u001B[39;49;00m(\u001B[34m1\u001B[39;49;00m, args.epochs + \u001B[34m1\u001B[39;49;00m):\r\n",
      "        model.train()\r\n",
      "        running_loss = \u001B[34m0.0\u001B[39;49;00m\r\n",
      "        \u001B[34mfor\u001B[39;49;00m i, (inputs, labels) \u001B[35min\u001B[39;49;00m tqdm(\u001B[36menumerate\u001B[39;49;00m(train_loader), total=\u001B[36mlen\u001B[39;49;00m(train_loader)):\r\n",
      "            \u001B[37m# get the inputs\u001B[39;49;00m\r\n",
      "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
      "\r\n",
      "            \u001B[37m# zero the parameter gradients\u001B[39;49;00m\r\n",
      "            optimizer.zero_grad()\r\n",
      "\r\n",
      "            \u001B[37m# forward + backward + optimize\u001B[39;49;00m\r\n",
      "            outputs = model(inputs)\r\n",
      "            loss = criterion(outputs, labels)\r\n",
      "            loss.backward()\r\n",
      "            optimizer.step()\r\n",
      "\r\n",
      "            \u001B[37m# print statistics\u001B[39;49;00m\r\n",
      "            running_loss += loss.item()\r\n",
      "            \u001B[34mif\u001B[39;49;00m i % \u001B[34m2000\u001B[39;49;00m == \u001B[34m1999\u001B[39;49;00m:  \u001B[37m# print every 2000 mini-batches\u001B[39;49;00m\r\n",
      "                \u001B[36mprint\u001B[39;49;00m(\u001B[33m\"\u001B[39;49;00m\u001B[33m[\u001B[39;49;00m\u001B[33m%d\u001B[39;49;00m\u001B[33m, \u001B[39;49;00m\u001B[33m%5d\u001B[39;49;00m\u001B[33m] loss: \u001B[39;49;00m\u001B[33m%.3f\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m % (epoch, i + \u001B[34m1\u001B[39;49;00m, running_loss / \u001B[34m2000\u001B[39;49;00m))\r\n",
      "                running_loss = \u001B[34m0.0\u001B[39;49;00m\r\n",
      "        val_acc = compute_accuracy(model=model, data_loader=val_loader, device=device)\r\n",
      "        reporter(epoch=epoch, val_acc=val_acc)\r\n",
      "    \u001B[36mprint\u001B[39;49;00m(\u001B[33m\"\u001B[39;49;00m\u001B[33mFinished Training\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "\u001B[34mif\u001B[39;49;00m \u001B[31m__name__\u001B[39;49;00m == \u001B[33m\"\u001B[39;49;00m\u001B[33m__main__\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m:\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\r\n",
      "        \u001B[33m\"\u001B[39;49;00m\u001B[33m--workers\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m,\r\n",
      "        default=\u001B[34m2\u001B[39;49;00m,\r\n",
      "        metavar=\u001B[33m\"\u001B[39;49;00m\u001B[33mW\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        help=\u001B[33m\"\u001B[39;49;00m\u001B[33mnumber of data loading workers (default: 2)\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \u001B[33m\"\u001B[39;49;00m\u001B[33m--epochs\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m,\r\n",
      "        default=\u001B[34m2\u001B[39;49;00m,\r\n",
      "        metavar=\u001B[33m\"\u001B[39;49;00m\u001B[33mE\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        help=\u001B[33m\"\u001B[39;49;00m\u001B[33mnumber of total epochs to run (default: 2)\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \u001B[33m\"\u001B[39;49;00m\u001B[33m--batch_size\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=\u001B[34m4\u001B[39;49;00m, metavar=\u001B[33m\"\u001B[39;49;00m\u001B[33mBS\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, help=\u001B[33m\"\u001B[39;49;00m\u001B[33mbatch size (default: 4)\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \u001B[33m\"\u001B[39;49;00m\u001B[33m--lr\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        \u001B[36mtype\u001B[39;49;00m=\u001B[36mfloat\u001B[39;49;00m,\r\n",
      "        default=\u001B[34m0.001\u001B[39;49;00m,\r\n",
      "        metavar=\u001B[33m\"\u001B[39;49;00m\u001B[33mLR\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        help=\u001B[33m\"\u001B[39;49;00m\u001B[33minitial learning rate (default: 0.001)\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \u001B[33m\"\u001B[39;49;00m\u001B[33m--dropout_rate\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        \u001B[36mtype\u001B[39;49;00m=\u001B[36mfloat\u001B[39;49;00m,\r\n",
      "        default=\u001B[34m0.0\u001B[39;49;00m,\r\n",
      "        metavar=\u001B[33m\"\u001B[39;49;00m\u001B[33mDR\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "        help=\u001B[33m\"\u001B[39;49;00m\u001B[33mdropout rate (default: 0.0)\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    parser.add_argument(\r\n",
      "        \u001B[33m\"\u001B[39;49;00m\u001B[33m--momentum\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mfloat\u001B[39;49;00m, default=\u001B[34m0.9\u001B[39;49;00m, metavar=\u001B[33m\"\u001B[39;49;00m\u001B[33mM\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, help=\u001B[33m\"\u001B[39;49;00m\u001B[33mmomentum (default: 0.9)\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--model-dir\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ.get(\u001B[33m'\u001B[39;49;00m\u001B[33mSM_MODEL_DIR\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33m./\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m))\r\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--smt_checkpoint_dir\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=\u001B[33m\"\u001B[39;49;00m\u001B[33m./\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\r\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--data-dir\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mstr\u001B[39;49;00m, default=os.environ.get(\u001B[33m'\u001B[39;49;00m\u001B[33mSM_CHANNEL_TRAINING\u001B[39;49;00m\u001B[33m'\u001B[39;49;00m, \u001B[33m\"\u001B[39;49;00m\u001B[33m./data/\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m),\r\n",
      "        help=\u001B[33m\"\u001B[39;49;00m\u001B[33mthe folder containing cifar-10-batches-py/\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    \u001B[37m# TODO num gpus\u001B[39;49;00m\r\n",
      "    parser.add_argument(\u001B[33m\"\u001B[39;49;00m\u001B[33m--num-gpus\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m, \u001B[36mtype\u001B[39;49;00m=\u001B[36mint\u001B[39;49;00m, default=\u001B[34m4\u001B[39;49;00m)\r\n",
      "\r\n",
      "    _train(parser.parse_args())\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize cifar10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e4ef1",
   "metadata": {},
   "source": [
    "Since the example requires cifar10 dataset, we first download it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e51f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0825135fb34d159b51544df4ddd49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils_cifar import get_train_data_loader, get_test_data_loader, imshow, classes\n",
    "\n",
    "trainloader = get_train_data_loader()\n",
    "testloader = get_test_data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98644f9",
   "metadata": {},
   "source": [
    "We are now all settled to launch tuning of hyperparameters in this particular case.\n",
    "\n",
    "The following code defines the search space for the hyperparameters (dropout, learning-rate, momentum) and the scheduler being used (Hyperband)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "from sagemaker_tune.backend.local_backend import LocalBackend\n",
    "from sagemaker_tune.tuner import Tuner\n",
    "from sagemaker_tune.search_space import loguniform, uniform\n",
    "from sagemaker_tune.stopping_criterion import StoppingCriterion\n",
    "from sagemaker_tune.optimizer.schedulers.hyperband import HyperbandScheduler\n",
    "\n",
    "\n",
    "max_epochs = 100\n",
    "config_space = {\n",
    "    \"epochs\": max_epochs,\n",
    "    \"lr\": loguniform(1e-5, 1e-1),\n",
    "    \"momentum\": uniform(0.8, 1.0),\n",
    "    \"dropout_rate\": loguniform(1e-5, 1.0),\n",
    "}\n",
    "\n",
    "\n",
    "scheduler = HyperbandScheduler(\n",
    "    config_space,\n",
    "    max_t=max_epochs,\n",
    "    resource_attr='epoch',\n",
    "    searcher='random',\n",
    "    metric=\"val_acc\",\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37fdda",
   "metadata": {},
   "source": [
    "We are now ready to define and launch the tuning of our hyperparameters.\n",
    "\n",
    "To do so, we define the number of workers that evaluates trials concurrently and how long we are willing to wait.\n",
    "\n",
    "Importantly, we use the local backend to evaluate our training script `\"cifar10.py\"`. This means that the tuning will run on the local machine with one subprocess per worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.utils.default_arguments:scheduler_options: Key 'resume': Imputing default value False\n",
      "scheduler_options: Key 'grace_period': Imputing default value 1\n",
      "scheduler_options: Key 'reduction_factor': Imputing default value 3\n",
      "scheduler_options: Key 'brackets': Imputing default value 1\n",
      "scheduler_options: Key 'type': Imputing default value stopping\n",
      "scheduler_options: Key 'searcher_data': Imputing default value rungs\n",
      "scheduler_options: Key 'do_snapshots': Imputing default value False\n",
      "scheduler_options: Key 'rung_system_per_bracket': Imputing default value True\n",
      "scheduler_options: Key 'rung_system_kwargs': Imputing default value {'cost_attr': 'elapsed_time', 'ranking_criterion': 'soft_ranking', 'epsilon': 1.0, 'epsilon_scaling': 1.0}\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.fifo:Master random_seed = 152531462\n",
      "INFO:sagemaker_tune.tuner:results of trials will be saved on /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[0: random]\n",
      "lr: 0.0010000000000000002\n",
      "momentum: 0.9\n",
      "dropout_rate: 0.003162277660168379\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 0 starts (first milestone = 1)\n",
      "INFO:root:Detected 4 GPUs\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.0010000000000000002 --momentum 0.9 --dropout_rate 0.003162277660168379 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/0/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 0) - scheduled config {'epochs': 30, 'lr': 0.0010000000000000002, 'momentum': 0.9, 'dropout_rate': 0.003162277660168379}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[1: random]\n",
      "lr: 0.04610158872973931\n",
      "momentum: 0.9917760272981655\n",
      "dropout_rate: 8.981823186090476e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 1 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.04610158872973931 --momentum 0.9917760272981655 --dropout_rate 8.981823186090476e-05 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/1/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 1) - scheduled config {'epochs': 30, 'lr': 0.04610158872973931, 'momentum': 0.9917760272981655, 'dropout_rate': 8.981823186090476e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[2: random]\n",
      "lr: 0.015477225160862805\n",
      "momentum: 0.9993711159241525\n",
      "dropout_rate: 0.030438411947590904\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 2 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.015477225160862805 --momentum 0.9993711159241525 --dropout_rate 0.030438411947590904 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/2/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 2) - scheduled config {'epochs': 30, 'lr': 0.015477225160862805, 'momentum': 0.9993711159241525, 'dropout_rate': 0.030438411947590904}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[3: random]\n",
      "lr: 0.0007548656000792128\n",
      "momentum: 0.8914123606025887\n",
      "dropout_rate: 0.0006155416075459008\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 3 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.0007548656000792128 --momentum 0.8914123606025887 --dropout_rate 0.0006155416075459008 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/3/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 3) - scheduled config {'epochs': 30, 'lr': 0.0007548656000792128, 'momentum': 0.8914123606025887, 'dropout_rate': 0.0006155416075459008}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate\n",
      "        0  InProgress     0      30  0.001000  0.900000      0.003162\n",
      "        1  InProgress     0      30  0.046102  0.991776      0.000090\n",
      "        2  InProgress     0      30  0.015477  0.999371      0.030438\n",
      "        3  InProgress     0      30  0.000755  0.891412      0.000616\n",
      "4 trials running, 0 finished (0 until the end), 35.10s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 3: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 3:1: metric = 0.452\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 0: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 0:1: metric = 0.451\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 2: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 2:1: metric = 0.099\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 1: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 1:1: metric = 0.102\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[4: random]\n",
      "lr: 0.00028359699503185216\n",
      "momentum: 0.9955804888600285\n",
      "dropout_rate: 0.061620141833751266\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.00028359699503185216 --momentum 0.9955804888600285 --dropout_rate 0.061620141833751266 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/4/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 4) - scheduled config {'epochs': 30, 'lr': 0.00028359699503185216, 'momentum': 0.9955804888600285, 'dropout_rate': 0.061620141833751266}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[5: random]\n",
      "lr: 2.1195616137125017e-05\n",
      "momentum: 0.9312098564506001\n",
      "dropout_rate: 1.1515677162544262e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 5 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 2.1195616137125017e-05 --momentum 0.9312098564506001 --dropout_rate 1.1515677162544262e-05 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/5/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 5) - scheduled config {'epochs': 30, 'lr': 2.1195616137125017e-05, 'momentum': 0.9312098564506001, 'dropout_rate': 1.1515677162544262e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[6: random]\n",
      "lr: 0.012367272242324848\n",
      "momentum: 0.8414639331712908\n",
      "dropout_rate: 0.17277241657821932\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 6 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.012367272242324848 --momentum 0.8414639331712908 --dropout_rate 0.17277241657821932 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/6/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 6) - scheduled config {'epochs': 30, 'lr': 0.012367272242324848, 'momentum': 0.8414639331712908, 'dropout_rate': 0.17277241657821932}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress     2      30  0.000755  0.891412      0.000616    2.0   0.5164         57.0\n",
      "        4  InProgress     0      30  0.000284  0.995580      0.061620      -        -            -\n",
      "        5  InProgress     0      30  0.000021  0.931210      0.000012      -        -            -\n",
      "        6  InProgress     0      30  0.012367  0.841464      0.172772      -        -            -\n",
      "7 trials running, 0 finished (0 until the end), 70.21s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 5: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 5:1: metric = 0.134\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 6: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 6:1: metric = 0.318\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 4:1: metric = 0.320\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[7: random]\n",
      "lr: 0.00013321633127427165\n",
      "momentum: 0.8448207256624178\n",
      "dropout_rate: 0.003129475724231145\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 7 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.00013321633127427165 --momentum 0.8448207256624178 --dropout_rate 0.003129475724231145 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/7/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 7) - scheduled config {'epochs': 30, 'lr': 0.00013321633127427165, 'momentum': 0.8448207256624178, 'dropout_rate': 0.003129475724231145}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[8: random]\n",
      "lr: 0.0019062096105654752\n",
      "momentum: 0.9404817707904609\n",
      "dropout_rate: 0.0754481792160604\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 8 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.0019062096105654752 --momentum 0.9404817707904609 --dropout_rate 0.0754481792160604 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/8/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 8) - scheduled config {'epochs': 30, 'lr': 0.0019062096105654752, 'momentum': 0.9404817707904609, 'dropout_rate': 0.0754481792160604}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 3: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 3:3: metric = 0.576\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress     3      30  0.000755  0.891412      0.000616    3.0   0.5756         86.0\n",
      "        4  InProgress     2      30  0.000284  0.995580      0.061620    2.0   0.3314         59.0\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012    1.0   0.1335         28.0\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772    1.0   0.3183         29.0\n",
      "        7  InProgress     0      30  0.000133  0.844821      0.003129      -        -            -\n",
      "        8  InProgress     0      30  0.001906  0.940482      0.075448      -        -            -\n",
      "9 trials running, 0 finished (0 until the end), 105.30s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 7: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 7:1: metric = 0.201\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 8: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 8:1: metric = 0.428\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[9: random]\n",
      "lr: 0.022124447622725994\n",
      "momentum: 0.8430060602854844\n",
      "dropout_rate: 0.008461110352238657\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 9 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.022124447622725994 --momentum 0.8430060602854844 --dropout_rate 0.008461110352238657 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/9/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 9) - scheduled config {'epochs': 30, 'lr': 0.022124447622725994, 'momentum': 0.8430060602854844, 'dropout_rate': 0.008461110352238657}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 4:3: metric = 0.307\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[10: random]\n",
      "lr: 0.004006519631110197\n",
      "momentum: 0.8052002719501925\n",
      "dropout_rate: 0.00014597879886690351\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 10 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.004006519631110197 --momentum 0.8052002719501925 --dropout_rate 0.00014597879886690351 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/10/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 10) - scheduled config {'epochs': 30, 'lr': 0.004006519631110197, 'momentum': 0.8052002719501925, 'dropout_rate': 0.00014597879886690351}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress     4      30  0.000755  0.891412      0.000616    4.0   0.5839        116.0\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620    3.0   0.3314         89.0\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012    1.0   0.1335         28.0\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772    1.0   0.3183         29.0\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129    1.0   0.2006         29.0\n",
      "        8  InProgress     2      30  0.001906  0.940482      0.075448    2.0   0.4692         59.0\n",
      "        9  InProgress     0      30  0.022124  0.843006      0.008461      -        -            -\n",
      "       10  InProgress     0      30  0.004007  0.805200      0.000146      -        -            -\n",
      "11 trials running, 0 finished (0 until the end), 140.40s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 9: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 9:1: metric = 0.212\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[11: random]\n",
      "lr: 0.0016969449471475235\n",
      "momentum: 0.9129634050867076\n",
      "dropout_rate: 0.9274977698805321\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 11 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.0016969449471475235 --momentum 0.9129634050867076 --dropout_rate 0.9274977698805321 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/11/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 11) - scheduled config {'epochs': 30, 'lr': 0.0016969449471475235, 'momentum': 0.9129634050867076, 'dropout_rate': 0.9274977698805321}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 8: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 8:3: metric = 0.499\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 10: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 10:1: metric = 0.461\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[12: random]\n",
      "lr: 1.7839681491650726e-05\n",
      "momentum: 0.937303273829865\n",
      "dropout_rate: 2.69324931071729e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 12 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 1.7839681491650726e-05 --momentum 0.937303273829865 --dropout_rate 2.69324931071729e-05 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/12/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 12) - scheduled config {'epochs': 30, 'lr': 1.7839681491650726e-05, 'momentum': 0.937303273829865, 'dropout_rate': 2.69324931071729e-05}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress     5      30  0.000755  0.891412      0.000616    5.0   0.5875        145.0\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620    3.0   0.3314         89.0\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012    1.0   0.1335         28.0\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772    1.0   0.3183         29.0\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129    1.0   0.2006         29.0\n",
      "        8  InProgress     3      30  0.001906  0.940482      0.075448    3.0   0.4993         88.0\n",
      "        9  InProgress     1      30  0.022124  0.843006      0.008461    1.0   0.2122         29.0\n",
      "       10  InProgress     1      30  0.004007  0.805200      0.000146    1.0   0.4606         30.0\n",
      "       11  InProgress     0      30  0.001697  0.912963      0.927498      -        -            -\n",
      "       12  InProgress     0      30  0.000018  0.937303      0.000027      -        -            -\n",
      "13 trials running, 0 finished (0 until the end), 175.50s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 11: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 11:1: metric = 0.212\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[13: random]\n",
      "lr: 0.005087392228189161\n",
      "momentum: 0.9501875079846022\n",
      "dropout_rate: 0.009853738653087536\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 13 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.005087392228189161 --momentum 0.9501875079846022 --dropout_rate 0.009853738653087536 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/13/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 13) - scheduled config {'epochs': 30, 'lr': 0.005087392228189161, 'momentum': 0.9501875079846022, 'dropout_rate': 0.009853738653087536}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 12: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 12:1: metric = 0.104\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[14: random]\n",
      "lr: 7.305641753938883e-05\n",
      "momentum: 0.8585023518471169\n",
      "dropout_rate: 0.0015411409785223203\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 14 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 7.305641753938883e-05 --momentum 0.8585023518471169 --dropout_rate 0.0015411409785223203 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/14/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 14) - scheduled config {'epochs': 30, 'lr': 7.305641753938883e-05, 'momentum': 0.8585023518471169, 'dropout_rate': 0.0015411409785223203}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress     6      30  0.000755  0.891412      0.000616    6.0   0.6202        174.0\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620    3.0   0.3314         89.0\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012    1.0   0.1335         28.0\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772    1.0   0.3183         29.0\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129    1.0   0.2006         29.0\n",
      "        8  InProgress     3      30  0.001906  0.940482      0.075448    3.0   0.4993         88.0\n",
      "        9  InProgress     1      30  0.022124  0.843006      0.008461    1.0   0.2122         29.0\n",
      "       10  InProgress     2      30  0.004007  0.805200      0.000146    2.0   0.5130         59.0\n",
      "       11  InProgress     1      30  0.001697  0.912963      0.927498    1.0   0.2125         28.0\n",
      "       12  InProgress     1      30  0.000018  0.937303      0.000027    1.0   0.1044         29.0\n",
      "       13  InProgress     0      30  0.005087  0.950188      0.009854      -        -            -\n",
      "       14  InProgress     0      30  0.000073  0.858502      0.001541      -        -            -\n",
      "15 trials running, 0 finished (0 until the end), 210.61s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 13: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 13:1: metric = 0.260\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[15: random]\n",
      "lr: 0.0033292057950927165\n",
      "momentum: 0.8101086085456705\n",
      "dropout_rate: 0.00012016041224707198\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 15 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.0033292057950927165 --momentum 0.8101086085456705 --dropout_rate 0.00012016041224707198 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/15/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 15) - scheduled config {'epochs': 30, 'lr': 0.0033292057950927165, 'momentum': 0.8101086085456705, 'dropout_rate': 0.00012016041224707198}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 10: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 10:3: metric = 0.533\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 14: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 14:1: metric = 0.138\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[16: random]\n",
      "lr: 0.0002806338775356367\n",
      "momentum: 0.8779602002155347\n",
      "dropout_rate: 6.770902056791205e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.0002806338775356367 --momentum 0.8779602002155347 --dropout_rate 6.770902056791205e-05 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/16/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 16) - scheduled config {'epochs': 30, 'lr': 0.0002806338775356367, 'momentum': 0.8779602002155347, 'dropout_rate': 6.770902056791205e-05}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress     8      30  0.000755  0.891412      0.000616    8.0   0.6261        233.0\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620    3.0   0.3314         89.0\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012    1.0   0.1335         28.0\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772    1.0   0.3183         29.0\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129    1.0   0.2006         29.0\n",
      "        8  InProgress     3      30  0.001906  0.940482      0.075448    3.0   0.4993         88.0\n",
      "        9  InProgress     1      30  0.022124  0.843006      0.008461    1.0   0.2122         29.0\n",
      "       10  InProgress     3      30  0.004007  0.805200      0.000146    3.0   0.5329         88.0\n",
      "       11  InProgress     1      30  0.001697  0.912963      0.927498    1.0   0.2125         28.0\n",
      "       12  InProgress     1      30  0.000018  0.937303      0.000027    1.0   0.1044         29.0\n",
      "       13  InProgress     1      30  0.005087  0.950188      0.009854    1.0   0.2604         28.0\n",
      "       14  InProgress     1      30  0.000073  0.858502      0.001541    1.0   0.1384         29.0\n",
      "       15  InProgress     0      30  0.003329  0.810109      0.000120      -        -            -\n",
      "       16  InProgress     0      30  0.000281  0.877960      0.000068      -        -            -\n",
      "17 trials running, 0 finished (0 until the end), 245.74s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 15: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 15:1: metric = 0.476\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 3: Reaches 9, continues to 27\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 3:9: metric = 0.616\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 16:1: metric = 0.321\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162      1   0.4510           29\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090      1   0.1020           29\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438      1   0.0992           29\n",
      "        3  InProgress     9      30  0.000755  0.891412      0.000616      9   0.6261          261\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620      3   0.3314           89\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012      1   0.1335           28\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772      1   0.3183           29\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129      1   0.2006           29\n",
      "        8  InProgress     3      30  0.001906  0.940482      0.075448      3   0.4993           88\n",
      "        9  InProgress     1      30  0.022124  0.843006      0.008461      1   0.2122           29\n",
      "       10  InProgress     4      30  0.004007  0.805200      0.000146      4   0.5838          116\n",
      "       11  InProgress     1      30  0.001697  0.912963      0.927498      1   0.2125           28\n",
      "       12  InProgress     1      30  0.000018  0.937303      0.000027      1   0.1044           29\n",
      "       13  InProgress     1      30  0.005087  0.950188      0.009854      1   0.2604           28\n",
      "       14  InProgress     1      30  0.000073  0.858502      0.001541      1   0.1384           29\n",
      "       15  InProgress     2      30  0.003329  0.810109      0.000120      2   0.5347           59\n",
      "       16  InProgress     1      30  0.000281  0.877960      0.000068      1   0.3206           29\n",
      "17 trials running, 0 finished (0 until the end), 280.83s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 15: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 15:3: metric = 0.555\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162      1   0.4510           29\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090      1   0.1020           29\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438      1   0.0992           29\n",
      "        3  InProgress    10      30  0.000755  0.891412      0.000616     10   0.6261          290\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620      3   0.3314           89\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012      1   0.1335           28\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772      1   0.3183           29\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129      1   0.2006           29\n",
      "        8  InProgress     3      30  0.001906  0.940482      0.075448      3   0.4993           88\n",
      "        9  InProgress     1      30  0.022124  0.843006      0.008461      1   0.2122           29\n",
      "       10  InProgress     5      30  0.004007  0.805200      0.000146      5   0.5838          148\n",
      "       11  InProgress     1      30  0.001697  0.912963      0.927498      1   0.2125           28\n",
      "       12  InProgress     1      30  0.000018  0.937303      0.000027      1   0.1044           29\n",
      "       13  InProgress     1      30  0.005087  0.950188      0.009854      1   0.2604           28\n",
      "       14  InProgress     1      30  0.000073  0.858502      0.001541      1   0.1384           29\n",
      "       15  InProgress     3      30  0.003329  0.810109      0.000120      3   0.5546           88\n",
      "       16  InProgress     2      30  0.000281  0.877960      0.000068      2   0.4280           58\n",
      "17 trials running, 0 finished (0 until the end), 315.90s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 16:3: metric = 0.491\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[17: random]\n",
      "lr: 6.960893628744843e-05\n",
      "momentum: 0.939802155771035\n",
      "dropout_rate: 0.00015779237014539643\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 17 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 6.960893628744843e-05 --momentum 0.939802155771035 --dropout_rate 0.00015779237014539643 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/17/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 17) - scheduled config {'epochs': 30, 'lr': 6.960893628744843e-05, 'momentum': 0.939802155771035, 'dropout_rate': 0.00015779237014539643}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  epochs        lr  momentum  dropout_rate  epoch  val_acc  worker-time\n",
      "        0  InProgress     1      30  0.001000  0.900000      0.003162    1.0   0.4510         29.0\n",
      "        1  InProgress     1      30  0.046102  0.991776      0.000090    1.0   0.1020         29.0\n",
      "        2  InProgress     1      30  0.015477  0.999371      0.030438    1.0   0.0992         29.0\n",
      "        3  InProgress    11      30  0.000755  0.891412      0.000616   11.0   0.6265        320.0\n",
      "        4  InProgress     3      30  0.000284  0.995580      0.061620    3.0   0.3314         89.0\n",
      "        5  InProgress     1      30  0.000021  0.931210      0.000012    1.0   0.1335         28.0\n",
      "        6  InProgress     1      30  0.012367  0.841464      0.172772    1.0   0.3183         29.0\n",
      "        7  InProgress     1      30  0.000133  0.844821      0.003129    1.0   0.2006         29.0\n",
      "        8  InProgress     3      30  0.001906  0.940482      0.075448    3.0   0.4993         88.0\n",
      "        9  InProgress     1      30  0.022124  0.843006      0.008461    1.0   0.2122         29.0\n",
      "       10  InProgress     7      30  0.004007  0.805200      0.000146    7.0   0.5838        206.0\n",
      "       11  InProgress     1      30  0.001697  0.912963      0.927498    1.0   0.2125         28.0\n",
      "       12  InProgress     1      30  0.000018  0.937303      0.000027    1.0   0.1044         29.0\n",
      "       13  InProgress     1      30  0.005087  0.950188      0.009854    1.0   0.2604         28.0\n",
      "       14  InProgress     1      30  0.000073  0.858502      0.001541    1.0   0.1384         29.0\n",
      "       15  InProgress     4      30  0.003329  0.810109      0.000120    4.0   0.5720        117.0\n",
      "       16  InProgress     3      30  0.000281  0.877960      0.000068    3.0   0.4915         87.0\n",
      "       17  InProgress     0      30  0.000070  0.939802      0.000158      -        -            -\n",
      "18 trials running, 0 finished (0 until the end), 351.00s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 17: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 17:1: metric = 0.266\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[18: random]\n",
      "lr: 0.009974136170988341\n",
      "momentum: 0.8485754783920574\n",
      "dropout_rate: 0.0009715170144344638\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 18 starts (first milestone = 1)\n",
      "INFO:root:running subprocess with command: /home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python blog-post/pytorch_cnn_cifar10/source/cifar10.py --epochs 30 --lr 0.009974136170988341 --momentum 0.8485754783920574 --dropout_rate 0.0009715170144344638 --smt_checkpoint_dir /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112/18/checkpoints\n",
      "INFO:sagemaker_tune.tuner:(trial 18) - scheduled config {'epochs': 30, 'lr': 0.009974136170988341, 'momentum': 0.8485754783920574, 'dropout_rate': 0.0009715170144344638}\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    backend=LocalBackend(entry_point=\"cifar10.py\"),\n",
    "    scheduler=scheduler,\n",
    "    stop_criterion=StoppingCriterion(max_wallclock_time=3600),\n",
    "    n_workers=4,\n",
    ")\n",
    "\n",
    "tuner.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f098985",
   "metadata": {},
   "source": [
    "As soon as the tuning starts, we see this line:\n",
    "\n",
    "```\n",
    "INFO:sagemaker_tune.tuner:results of trials will be saved on /home/ec2-user/sagemaker-tune/cifar10-2021-11-05-08-09-35-112\n",
    "```\n",
    "\n",
    "All the log of the trials are stored there for further analysis.\n",
    "\n",
    "At any time during the tuning, we can easily get the results obtained so far by calling \n",
    "`load_experiment(\"cifar10-2021-11-04-17-26-30-169\")` and then plot the best result obtained since the start of the tuning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a144610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment cifar10-2021-11-04-17-26-30-169 contains 474 evaluations from 125 trials when tuning val_acc on cifar10 with HyperbandScheduler.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcY0lEQVR4nO3deZgddZ3v8fcnHZJAEpaQDoHsQFiCsjaboIR9cQmoMwYVhKsTmUcuMF6ekRm9DOjoHVTQ6wXMoJNh1YAoGDAMKLIKSBIMS8BACCE0WzohARKWLP29f9SvmcrhdOd009XndJ/P63nOk1p+VfU9le7z6fpVnSpFBGZmVt/6VbsAMzOrPoeBmZk5DMzMzGFgZmY4DMzMDIeBmZnhMLAyJH1B0h258UMkPSNptaQTq1haTZJ0gaRre8u2JI2XFJL6d1NNSyQd1d1trWc5DOx9IuK6iDgmN+nbwKURMSQibu7s+iQNkHRj+iAISZNL5kvSRZJWpNf3JamD9V0p6V9LpnXrB1xvIenLkv4q6U1Jr0r6naSh1a7Leh+HgVViHLCgKwvmPpzvB74IvFKm2TTgRGAvYE/gE8BXu7K9nlbN8JF0GPA94OSIGArsDtxQrXqKVG8hXw0OgzonaYyk30hqSX+VXyrpNEn3p/nPAjsCt6RuooGSTpf0VPprdLGkr+bWN1lSs6RvSHoF+M+IWBsRP46I+4ENZcr4EnBxRDRHxIvAxcBpH+A97Z/+Su6fm/YZSfPT8AXpSOX69B4ekbRXru0Okn6d9slzks7KzWtb9lpJb+TqHNTB+s6T9Gya96Skk3LzTpN0v6QfSlqZtnd8bv4ESfekZX8PDM+91f2BByPiLwAR8VpEXBURb6ZlN5d0saTnJb2etrN5bvkvSFoqabmkb+a22S9X8wpJN0galpt/Slrnivxyad5GR21tPw/t/D+1u53ckd6XJS0F/lhuHdZ9HAZ1TFIDcCvwPDAeGAXMzLeJiJ2ApcAnUzfRu8Aysr/etwROB34kad/cYiOBYWRHFNMqKGUP4NHc+KNpWpdExBxgBXB0bvIXgWty41OAX6U6fwHcLGkzSf2AW1INo4AjgXMkHVuy7I3A1sB1Ha0vzXsW+CiwFXAhcK2k7XPrOxBYSPZB/33gP3LdZL8A5qV53yELzjZ/Bo6VdKGy8zoDS3bFD4H9gI+kuv4RaM3NPxTYNb3H8yXtnqafRXakdhiwA7ASuAxA0iTgp8Apad62wGi6pt3t5BxGdsRzLFasiPCrTl/AwUAL0L9k+mnA/bnxJcBRHaznZuDsNDwZWAsMaqdtMzC5ZNoGYLfc+EQgALWzjiuBd4BVudcbaZn+qc03gOvS8DDgLWD7NH4B8FBuff2Al8k+sA8ElpZs75/IjnDalr23ZH6762un/vnAlNy+XpSbt0V6HyOBscB6YHBu/i+Aa3Pjx5OF1ypgNXAJ0JBqeBvYq8z2x6dtjM5NexiYmoafAo7MzdseWAf0B84HZubmDU7/30fl/m/+NTd/MtBc7mdpE9tpq3HHav+e1MvL/XD1bQzwfESs78xCqRvjX4BdyD50tgAezzVpiYh3OrHK1WRHGW22BFZHREj6Z+Cf0/RrI+KMNPzDiPhWrqbxwHO5dVwLPCVpCPC3wH0R8XJu/gttAxHRmroydiD7ANpB0qpc2wbgvnLLVrA+JJ0KfJ3sAw5gCBt397ySW/atdFDQ1mZlRKzJtX2e7P+trf1twG3piOZwsqOThcBNwCCyo5L25M/fvJW2CdkR3U2S8kcRG4Dt0nvKv9c1klZ0sI2OdLSdNuX2tRXA3UT17QVgbGdOzqWuiF+TdUFsFxFbA7OB/NU/nb0V7gKyk8dt9krTiIjvRdY9NSQXBJsU2bmHB4GTyLo0rilp8t4HavogHQ28RLZPnouIrXOvoRFxQn71ZTZZdn2SxgE/A84Etk376wk23l/teRnYRtLg3LSx7bzf1oi4k6xv/UPAcrKjp50q2E6pF4DjS/bBoLRPX2bj97oFWVdRmzVkfxy0GdnF7bz31rpQv3WBw6C+PUz2y/1vkgZLGiTpkE0sMwAYSNa9tD4dJRzT8SJZiEga1LaOtK22D8Srga9LGiVpB+B/kXU3fFBXk/WTf5jsL+W8/SR9OgXhOcC7wENk++SNdAJ8c0kNkj4kaf9NbKu99Q0m+0BrAZB0OtmH9SZFxPPAXOBCZZfnHgp8sm2+pCmSpkraRpkDyPrYH4qIVmAGcImyE+INkg4uc16hnOnAd1OQIalR0pQ070bgE5IOlTSA7LLj/OfIfOAEScMkjUz7oivbsR7mMKhjEbGB7MNlZ7KTxM3A5zaxzJtkJ/5uIDvh93lgVgWbW0jWhz0KuD0Nj0vz/p2s3/txsr+af5emfVA3pW3cVNLVAvBbsve6kuzI4dMRsS63T/Ym63ZaDvyc7ORvR9pb35NkV0c9CLxKFkx/6sR7+DzZeYzXyLrmrs7NWwn8HfAM2TmTa4EfRETbSe1zyfbpnLT8RVT2O/9/yf5P75D0JlmoHQgQEQuAr5Gdu3g51ZC/WugaspPvS4A7gOu7sh3reYrwUZj1Xcoujf1qRPwhN+0CYOeI+GLVCjOrMT4ysD5L0mfIumh8jbrZJvhqIuuTJN0NTAJOSf3nZtYBdxOZmZm7iczMrJd2Ew0fPjzGjx9f7TLMzHqVefPmLY+IxnLzemUYjB8/nrlz51a7DDOzXkXS8+3NczeRmZk5DMzMzGFgZmY4DMzMDIeBmZnhMDAzMxwGZmZGL/2egZl1j9bW4MoHlrDqrbXVLsUqdNiuI9hv3Dbdvl6HgVkde/61t/j2rU8CoEqevWZVt9UWAxwG1nutXd/K+tbyNw/9xZ+X8sSLr/dwRQbw5jvZ469/cvI+fGqvHapcjVWTw6CHPLJ0JYtbSh+2VR9WrH6X/3PbXzfZbty2W2yyjXW/XbYbwm4jh1a7DKsyh0EPeLz5dT59+QPVLqPqjthtBAdOGFZ23rF7jGT88MFl55lZ8RwG3WzuktdoXvk2AI+/+DoPLV7Bq2+8y7DBA7jhqwcxsH9DlSusjoH9+zFiy0HVLsPM2uEw6EYbWoOTf/YQ6zZkDwzqJzhk5+Fsv9XmnHrwOHYe4UNxM6tNDoMK3TivmXnPv9Zhm9ZWWLchOP2Q8Zx68HiGDurP8CEDe6hCM7OucxhUICL4zq1Psm5DK0MGdrzLtt9qEB+b2MgE93+bWS/iMKjAyrfW8frb6/jWx3fnKx/dsdrlmJl1O9+OogLPLV8NwI6N/mvfzPqmwsNA0nGSFkpaJOm8dtpMljRf0gJJ9xRdU2e1fT9gwvAhVa7EzKwYhXYTSWoALgOOBpqBOZJmRcSTuTZbA5cDx0XEUkkjiqypK5asWEP/fmL0NptXuxQzs0IUfWRwALAoIhZHxFpgJjClpM3ngd9ExFKAiFhWcE2d9tzyNYwdtgWbNbhXzcz6pqI/3UYBL+TGm9O0vF2AbSTdLWmepFPLrUjSNElzJc1taWkpqNzyFres8dVBZtanFR0G5e6DGCXj/YH9gI8DxwL/W9Iu71so4oqIaIqIpsbGxu6vtB2trcGSFWt8qwQz69OKvrS0GRiTGx8NvFSmzfKIWAOskXQvsBfwdMG1dWjt+lYuvWsRMx9eyjvrWn1kYGZ9WtFhMAeYKGkC8CIwlewcQd5vgUsl9QcGAAcCPyq4rg5dcsdCfvLHRQAcudsIxgzbguM+NLKaJZmZFarQMIiI9ZLOBG4HGoAZEbFA0hlp/vSIeErSfwGPAa3AzyPiiSLr6sirb7zDv9+7mJ0aB/Otj0/i8N1q7uImM7NuV/g3kCNiNjC7ZNr0kvEfAD8oupZKXH7XIja0Bv952gGM9f31zaxO+FrJnBdXvc0vH36Bv2ka7SAws7riMEjeXruBKZfeTxCcecTEapdjZtajHAbJy6+/zfLVazlk5+GM2trfNDaz+uIwKHHSPqXfiTMz6/scBmZm5jAwMzOHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZvTAXUtrXUSwdkMr6zaUPoDNzKx+1H0YXHjLk1z5wJL3xhv6lXtSp5lZ31b3YbB4+Rq232oQXzxoHAP792Pyrn6YjZnVn7oPA4DtthzE1w7fudplmJlVTd2GwSW/f5r7nmlh0bLV7NQ4pNrlmJlVVd2GwW/nv8hbazew95it/bB7M6t7dRsGAIfstC0/nrpPtcswM6s6f8/AzMwcBmZm5jAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZvRAGEg6TtJCSYsknVdm/mRJr0uan17nF12TmZltrNBvIEtqAC4DjgaagTmSZkXEkyVN74uITxRZi5mZta/oI4MDgEURsTgi1gIzgSkFb9PMzDqp6DAYBbyQG29O00odLOlRSbdJ2qPciiRNkzRX0tyWlpYiajUzq1tFh0G5x4aVPl/yEWBcROwF/D/g5nIriogrIqIpIpoaGxu7t0ozszpXdBg0A2Ny46OBl/INIuKNiFidhmcDm0kaXnBdZmaWU3QYzAEmSpogaQAwFZiVbyBppCSl4QNSTSsKrsvMzHIKvZooItZLOhO4HWgAZkTEAklnpPnTgc8Cfy9pPfA2MDUiSruSzMysQIU/3CZ1/cwumTY9N3wpcGnRdZiZWfv8DWQzM3MYmJmZw8DMzHAYmJkZDgMzM8NhYGZm9MClpbXmrbXr2dAatPqrDGZm76mrMLhjwStMu2bee+MHTti2itWYmdWOugqDl1a9DcDXj96FLQY0cOTu21W5IjOz2lBXYdDmlIPGsc3gAdUuw8ysZvgEspmZOQzMzMxhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkVhoGkgyQNzY0PlXRgcWWZmVlPqvTI4KfA6tz4mjRtkyQdJ2mhpEWSzuug3f6SNkj6bIU1mZlZN6k0DBQR0TYSEa1U8PxkSQ3AZcDxwCTgZEmT2ml3EXB7hfWYmVk3qjQMFks6S9Jm6XU2sLiC5Q4AFkXE4ohYC8wEppRp9z+BXwPLKqzHzMy6UaVhcAbwEeBFoBk4EJhWwXKjgBdy481p2nskjQJOAqZXWIuZmXWzTXb1AETEMmBqF9avcqsrGf8x8I2I2CCVa55WJE0jBdDYsWO7UIqZmbWn0quJrpK0dW58G0kzKli0GRiTGx8NvFTSpgmYKWkJ8Fngckknlq4oIq6IiKaIaGpsbKykbDMzq1BFRwbAnhGxqm0kIlZK2qeC5eYAEyVNIOtimgp8Pt8gIia0DUu6Erg1Im6usC4zM+sGlYZBP0nbRMRKAEnDKlk2ItZLOpPsKqEGYEZELJB0Rprv8wRmZjWg0jC4GHhA0o1p/G+A71ayYETMBmaXTCsbAhFxWoX1mJlZN6r0BPLVkuYBh5OdFP50RDxZaGVmZtZjKj0yIHXvtACDACSNjYilhVVmZmY9ptKriT4l6RngOeAeYAlwW4F1mZlZD6r0S2ffAQ4Cnk5X/xwJ/KmwqszMrEdVGgbrImIF2VVF/SLiLmDv4soyM7OeVOk5g1WShgD3AtdJWgasL64sMzPrSZUeGUwB3gL+Afgv4Fngk0UVZWZmPavSS0vXpMFW4KrS+ZIejIiDu7MwMzPrOd312MtB3bQeMzOrgu4Kg9I7kZqZWS/SXWFgZma9WHeFQfsPIjAzs5rXXWFwSjetx8zMqqDDq4kkvUn58wECIiK2JBt4ooDazMysh3QYBhExtKcKMTOz6qn4rqUAkkaQu4zUdy01M+sbfNdSMzPzXUvNzMx3LTUzMzp/19L78F1Lzcz6nEqPDO4FtgbOxnctNTPrcyoNAwG3A3cDQ4DrU7eRmZn1ARWFQURcGBF7AF8DdgDukfSHQiszM7Me09nbUSwDXgFWACO6vxwzM6uGSr9n8PeS7gbuBIYDfxcRexZZmJmZ9ZxKryYaB5wTEfMLrMXMzKqk0sdenld0IWZmVj1+uI2ZmTkMzMysB8JA0nGSFkpaJOl93U2Spkh6TNJ8SXMlHVp0TWZmtrFO3cK6syQ1AJcBRwPNwBxJsyLiyVyzO4FZERGS9gRuAHYrsi4zM9tY0UcGBwCLImJxRKwFZgJT8g0iYnVEtD1NbTDln6xmZmYFKjoMRgEv5Mab07SNSDpJ0l+B3wH/o9yKJE1L3UhzW1paCinWzKxeFR0GKjPtfX/5R8RNEbEbcCLZsxPev1DEFRHRFBFNjY2N3VulmVmdKzoMmoExufHRwEvtNY6Ie4GdJA0vuC4zM8spOgzmABMlTZA0AJgKzMo3kLSzJKXhfYEBZPc+MjOzHlLo1UQRsV7SmWS3v24AZkTEAklnpPnTgc8Ap0paB7wNfC53QtnMzHpAoWEAEBGzgdkl06bnhi8CLiq6DjMza5+/gWxmZg4DMzNzGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzOjB8JA0nGSFkpaJOm8MvO/IOmx9HpA0l5F12RmZhsrNAwkNQCXAccDk4CTJU0qafYccFhE7Al8B7iiyJrMzOz9ij4yOABYFBGLI2ItMBOYkm8QEQ9ExMo0+hAwuuCazMysRNFhMAp4ITfenKa158vAbeVmSJomaa6kuS0tLd1YopmZFR0GKjMtyjaUDicLg2+Umx8RV0REU0Q0NTY2dmOJZmbWv+D1NwNjcuOjgZdKG0naE/g5cHxErCi4JjMzK1H0kcEcYKKkCZIGAFOBWfkGksYCvwFOiYinC67HzMzKKPTIICLWSzoTuB1oAGZExAJJZ6T504HzgW2ByyUBrI+IpiLrMjOzjRXdTUREzAZml0ybnhv+CvCVouswM7P2+RvIZmbmMDAzM4eBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzM3ogDCQdJ2mhpEWSziszfzdJD0p6V9K5RddjZmbv17/IlUtqAC4DjgaagTmSZkXEk7lmrwFnAScWWYuZmbWv6CODA4BFEbE4ItYCM4Ep+QYRsSwi5gDrCq6FccMHc8KHR7JZf/eOmZnlFXpkAIwCXsiNNwMHdmVFkqYB0wDGjh3bpWIO33UEh+86okvLmpn1ZUX/iawy06IrK4qIKyKiKSKaGhsbP2BZZmaWV3QYNANjcuOjgZcK3qaZmXVS0WEwB5goaYKkAcBUYFbB2zQzs04q9JxBRKyXdCZwO9AAzIiIBZLOSPOnSxoJzAW2BFolnQNMiog3iqzNzMz+W9EnkImI2cDskmnTc8OvkHUfmZlZlfgaSzMzcxiYmZnDwMzMAEV06bL/qpLUAjzfiUWGA8sLKqe7udZi9JZae0ud4FqLUHSd4yKi7Be1emUYdJakuRHRVO06KuFai9Fbau0tdYJrLUI163Q3kZmZOQzMzKx+wuCKahfQCa61GL2l1t5SJ7jWIlStzro4Z2BmZh2rlyMDMzPrgMPAzMz6fhhs6hnMVahniaTHJc2XNDdNGybp95KeSf9uk2v/T6n2hZKOLbi2GZKWSXoiN63TtUnaL73HRZJ+Iqnccy2KqPUCSS+mfTtf0gnVrlXSGEl3SXpK0gJJZ6fpNbdfO6i1FvfrIEkPS3o01Xphml5T+7WDOmtunxIRffZFdqfUZ4EdgQHAo2R3RK1mTUuA4SXTvg+cl4bPAy5Kw5NSzQOBCem9NBRY28eAfYEnPkhtwMPAwWQPN7oNOL6Har0AOLdM26rVCmwP7JuGhwJPp3pqbr92UGst7lcBQ9LwZsCfgYNqbb92UGfN7dO+fmSwyWcw14gpwFVp+CrgxNz0mRHxbkQ8Bywie0+FiIh7gdc+SG2Stge2jIgHI/sJvjq3TNG1tqdqtUbEyxHxSBp+E3iK7HGwNbdfO6i1PdWsNSJidRrdLL2CGtuvHdTZnqrt074eBuWewdzRD3dPCOAOSfOUPdcZYLuIeBmyX0ig7UHNtVB/Z2sblYZLp/eUMyU9lrqR2roIaqJWSeOBfcj+Oqzp/VpSK9TgfpXUIGk+sAz4fUTU5H5tp06osX3a18Og257B3I0OiYh9geOBr0n6WAdta7H+Nu3VVs2afwrsBOwNvAxcnKZXvVZJQ4BfA+dExw9uqsVaa3K/RsSGiNib7HkoB0j6UAfNq1ZrO3XW3D7t62FQc89gjoiX0r/LgJvIun1eTYeBpH+Xpea1UH9na2tm44cV9VjNEfFq+sVrBX7Gf3epVbVWSZuRfbheFxG/SZNrcr+Wq7VW92ubiFgF3A0cR43u19I6a3Gf9vUwqKlnMEsaLGlo2zBwDPBEqulLqdmXgN+m4VnAVEkDJU0AJpKdROpJnaotHZq/KemgdLXDqbllCtX2IZCcRLZvq1prWu9/AE9FxCW5WTW3X9urtUb3a6OkrdPw5sBRwF+psf3aXp21uE+77Ux0rb6AE8iuingW+GaVa9mR7EqBR4EFbfUA2wJ3As+kf4fllvlmqn0hBVyVU1LfL8kOWdeR/SXy5a7UBjSlH+5ngUtJ33TvgVqvAR4HHiP7pdq+2rUCh5Idzj8GzE+vE2pxv3ZQay3u1z2Bv6SangDO7+rvUpG1dlBnze1T347CzMz6fDeRmZlVwGFgZmYOAzMzcxiYmRkOAzMzw2FgdU7S3ZKa0vASScM7aHuBpHO7sI3Jkm7dRJu9S+5c+SnVwF12rX44DMxqw95k1/QDEBGzIuLfqleO1RuHgfV6kv5R0llp+EeS/piGj5R0bRr+qaS5+XvKb2Kdp6abiD0q6Zoy8/eW9FBqc1PbjcYk7SzpD2m5RyTtVLLc/pL+ImnH3LQBwLeBzym7t/3nJJ0m6dI0/8pU/12SFks6LN3c7ClJV+bWc4ykB9N2f5XuMWRWEYeB9QX3Ah9Nw03AkHSPnUOB+9L0b0ZEE9k3Qg+TtGd7K5O0B9m3QI+IiL2As8s0uxr4RkTsSfZN0n9J068DLkvLfYTsW9Jt6/0IMB2YEhGL26ZHdnv184HrI2LviLi+zPa2AY4A/gG4BfgRsAfw4RRMw4FvAUdFdiPEucDX23uPZqX6V7sAs24wD9gv3ffpXeARslD4KHBWavO3ym4Z3p/sIS6TyG4FUM4RwI0RsRwgIjZ6boKkrYCtI+KeNOkq4Fdp+6Mi4qa03DupPcDuwBXAMZFuVthJt0RESHoceDUiHk/rXgCMJ7tx2STgT2l7A4AHu7Adq1MOA+v1ImKdpCXA6cADZB/yh5PdIvipdMOvc4H9I2Jl6loZ1MEqRdduD9zRYwhfTtvch67dbfLd9G9rbrhtvD+wgexe+Sd3Yd1m7iayPuNesg/8e8m6hs4A5kd2860tgTXA65K2I3uWREfuJDuS2Bay5+rmZ0bE68BKSW1dU6cA90R27/9mSSem5QZK2iK1WQV8HPiepMlltvkm2aMmu+oh4BBJO6dtbyFplw+wPqszDgPrK+4j6/55MCJeBd5J04iIR8nuHLkAmAH8qaMVRcQC4LvAPZIeBS4p0+xLwA8kPUZ2JdC30/RTgLPS9AeAkbn1vgp8ErhM0oEl67sLmNR2ArnSN51bdwtwGvDLtO2HgN06ux6rX75rqZmZ+cjAzMwcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwM+P/Tmmb3ZC+0DgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker_tune.experiments import load_experiment\n",
    "from sagemaker_tune.constants import SMT_TUNER_TIME\n",
    "tuning_experiment = load_experiment(\"cifar10-2021-11-04-17-26-30-169\")\n",
    "print(tuning_experiment)\n",
    "df = tuning_experiment.results.sort_values(SMT_TUNER_TIME)\n",
    "tuning_experiment.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd66ec",
   "metadata": {},
   "source": [
    "A lot more of information is also available since all the results obtained over time are stored. For instance, we can plot the metric obtained for each trials over time (recall that 4 trials were running asynchronously).\n",
    "We clearly see the effect of Hyperband that only lets the trials with best results continue training. This allows to drastically speed-up the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0082576b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "cmap = cm.get_cmap(\"Set2\")\n",
    "for trial_id in sorted(df.trial_id.unique()):\n",
    "    dd = df[df.trial_id == trial_id]\n",
    "    plt.plot(\n",
    "        dd[SMT_TUNER_TIME],\n",
    "        dd[tuning_experiment.metric_name()],\n",
    "        marker='.', color=cmap(trial_id % len(cmap.colors)), label=trial_id\n",
    "    )\n",
    "plt.xlabel(\"Wallclock time\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "plt.title(\"Trial performance over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa2de7",
   "metadata": {},
   "source": [
    "The previous example showed how to tune hyperparameter on a local machine. It can be used to tune your hyperparameters or your own machine for instance. \n",
    "\n",
    "Sometimes, we need more powerful machine or a larger number which motivates the use of cloud ressources. In those cases, SageMaker tune provides a very simple way to run tuning on Sagemaker. Let us have a look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23114a",
   "metadata": {},
   "source": [
    "We first upload cifar10 dataset to s3 so that it is available on cloud machines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=\"data\", bucket=bucket, key_prefix=\"data/cifar10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01861897",
   "metadata": {},
   "source": [
    "We now define our new backend to specify that we want trials to be executed on SageMaker. \n",
    "We use SageMaker framework (`PyTorch`) in this particular example since we have a pytorch training script but any SageMaker framework can be used (XGBoost, TensorFlow, SKlearn, HuggingFace, ...). \n",
    "\n",
    "If you do not know what a SageMaker framework is, it is a Python wrapper that allows you to run Machine Learning code easily by providing pre-made docker images that works seamlessly on CPU and GPU for many framework versions. In this particular example for instance, all we need to do is to instantiate the wrapper PyTorch with our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4d1e04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_utils:No Sagemaker role passed as environment variable $AWS_ROLE, inferring it.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker_tune.backend.sagemaker_backend.sagemaker_utils import get_execution_role\n",
    "from sagemaker_tune.backend.sagemaker_backend.sagemaker_backend import SagemakerBackend\n",
    "\n",
    "backend = SagemakerBackend(\n",
    "    sm_estimator=PyTorch(\n",
    "        entry_point=\"./cifar10.py\",\n",
    "        instance_type=\"ml.g4dn.xlarge\",\n",
    "        instance_count=1,\n",
    "        role=get_execution_role(),\n",
    "        framework_version='1.7.1',\n",
    "        py_version='py3',\n",
    "    ),\n",
    "    inputs=inputs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0309f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.utils.default_arguments:scheduler_options: Key 'resume': Imputing default value False\n",
      "scheduler_options: Key 'grace_period': Imputing default value 1\n",
      "scheduler_options: Key 'reduction_factor': Imputing default value 3\n",
      "scheduler_options: Key 'brackets': Imputing default value 1\n",
      "scheduler_options: Key 'type': Imputing default value stopping\n",
      "scheduler_options: Key 'searcher_data': Imputing default value rungs\n",
      "scheduler_options: Key 'do_snapshots': Imputing default value False\n",
      "scheduler_options: Key 'rung_system_per_bracket': Imputing default value True\n",
      "scheduler_options: Key 'rung_system_kwargs': Imputing default value {'cost_attr': 'elapsed_time', 'ranking_criterion': 'soft_ranking', 'epsilon': 1.0, 'epsilon_scaling': 1.0}\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.fifo:Master random_seed = 1169040168\n"
     ]
    }
   ],
   "source": [
    "scheduler = HyperbandScheduler(\n",
    "    config_space,\n",
    "    max_t=max_epochs,\n",
    "    resource_attr='epoch',\n",
    "    searcher='random',\n",
    "    metric=\"val_acc\",\n",
    "    mode=\"max\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef6ade",
   "metadata": {},
   "source": [
    "We can now run again our tuning, this time we use 20 workers each having its own GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6467394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker_tune.tuner:results of trials will be saved on /home/ec2-user/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[4: random]\n",
      "lr: 0.0013501495289833228\n",
      "momentum: 0.8972614760043784\n",
      "dropout_rate: 0.0007195933427612641\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4 starts (first milestone = 1)\n",
      "INFO:root:Trial 4 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/4/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-4\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-4 for trial-id 4\n",
      "INFO:sagemaker_tune.tuner:(trial 4) - scheduled config {'epochs': 30, 'lr': 0.0013501495289833228, 'momentum': 0.8972614760043784, 'dropout_rate': 0.0007195933427612641}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[5: random]\n",
      "lr: 0.044986758788531235\n",
      "momentum: 0.9897081102962482\n",
      "dropout_rate: 0.06482606754846802\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 5 starts (first milestone = 1)\n",
      "INFO:root:Trial 5 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/5/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-5\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-5 for trial-id 5\n",
      "INFO:sagemaker_tune.tuner:(trial 5) - scheduled config {'epochs': 30, 'lr': 0.044986758788531235, 'momentum': 0.9897081102962482, 'dropout_rate': 0.06482606754846802}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[6: random]\n",
      "lr: 9.96803204188183e-05\n",
      "momentum: 0.9815578445415271\n",
      "dropout_rate: 4.845073533081376e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 6 starts (first milestone = 1)\n",
      "INFO:root:Trial 6 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/6/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-6\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-6 for trial-id 6\n",
      "INFO:sagemaker_tune.tuner:(trial 6) - scheduled config {'epochs': 30, 'lr': 9.96803204188183e-05, 'momentum': 0.9815578445415271, 'dropout_rate': 4.845073533081376e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[7: random]\n",
      "lr: 0.04395717369373465\n",
      "momentum: 0.9518406498779792\n",
      "dropout_rate: 0.0031301595169842002\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 7 starts (first milestone = 1)\n",
      "INFO:root:Trial 7 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/7/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-7\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-7 for trial-id 7\n",
      "INFO:sagemaker_tune.tuner:(trial 7) - scheduled config {'epochs': 30, 'lr': 0.04395717369373465, 'momentum': 0.9518406498779792, 'dropout_rate': 0.0031301595169842002}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[8: random]\n",
      "lr: 1.8160622809807093e-05\n",
      "momentum: 0.9070136946704399\n",
      "dropout_rate: 0.016231703331156425\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 8 starts (first milestone = 1)\n",
      "INFO:root:Trial 8 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/8/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-8\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-8 for trial-id 8\n",
      "INFO:sagemaker_tune.tuner:(trial 8) - scheduled config {'epochs': 30, 'lr': 1.8160622809807093e-05, 'momentum': 0.9070136946704399, 'dropout_rate': 0.016231703331156425}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[9: random]\n",
      "lr: 7.044882299066996e-05\n",
      "momentum: 0.9969300743976542\n",
      "dropout_rate: 0.006160879081432976\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 9 starts (first milestone = 1)\n",
      "INFO:root:Trial 9 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/9/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-9\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-9 for trial-id 9\n",
      "INFO:sagemaker_tune.tuner:(trial 9) - scheduled config {'epochs': 30, 'lr': 7.044882299066996e-05, 'momentum': 0.9969300743976542, 'dropout_rate': 0.006160879081432976}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[10: random]\n",
      "lr: 6.36588503205043e-05\n",
      "momentum: 0.8172521529211448\n",
      "dropout_rate: 0.0013119683908169907\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 10 starts (first milestone = 1)\n",
      "INFO:root:Trial 10 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/10/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-10\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-10 for trial-id 10\n",
      "INFO:sagemaker_tune.tuner:(trial 10) - scheduled config {'epochs': 30, 'lr': 6.36588503205043e-05, 'momentum': 0.8172521529211448, 'dropout_rate': 0.0013119683908169907}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[11: random]\n",
      "lr: 0.0007650008305444999\n",
      "momentum: 0.8006839519615782\n",
      "dropout_rate: 0.03024734394208512\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 11 starts (first milestone = 1)\n",
      "INFO:root:Trial 11 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/11/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-11\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-11 for trial-id 11\n",
      "INFO:sagemaker_tune.tuner:(trial 11) - scheduled config {'epochs': 30, 'lr': 0.0007650008305444999, 'momentum': 0.8006839519615782, 'dropout_rate': 0.03024734394208512}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[12: random]\n",
      "lr: 0.03943640506362324\n",
      "momentum: 0.9516270560791906\n",
      "dropout_rate: 1.7356007919916057e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 12 starts (first milestone = 1)\n",
      "INFO:root:Trial 12 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/12/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-12\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-12 for trial-id 12\n",
      "INFO:sagemaker_tune.tuner:(trial 12) - scheduled config {'epochs': 30, 'lr': 0.03943640506362324, 'momentum': 0.9516270560791906, 'dropout_rate': 1.7356007919916057e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[13: random]\n",
      "lr: 2.6144398286045108e-05\n",
      "momentum: 0.9772935774024035\n",
      "dropout_rate: 0.00035018031073134556\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 13 starts (first milestone = 1)\n",
      "INFO:root:Trial 13 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/13/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-13\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-13 for trial-id 13\n",
      "INFO:sagemaker_tune.tuner:(trial 13) - scheduled config {'epochs': 30, 'lr': 2.6144398286045108e-05, 'momentum': 0.9772935774024035, 'dropout_rate': 0.00035018031073134556}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[14: random]\n",
      "lr: 0.018400457758982008\n",
      "momentum: 0.8974084272528793\n",
      "dropout_rate: 0.14786856720960723\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 14 starts (first milestone = 1)\n",
      "INFO:root:Trial 14 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/14/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-14\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-14 for trial-id 14\n",
      "INFO:sagemaker_tune.tuner:(trial 14) - scheduled config {'epochs': 30, 'lr': 0.018400457758982008, 'momentum': 0.8974084272528793, 'dropout_rate': 0.14786856720960723}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[15: random]\n",
      "lr: 7.170865384238529e-05\n",
      "momentum: 0.8825415159505524\n",
      "dropout_rate: 0.051994157891957805\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 15 starts (first milestone = 1)\n",
      "INFO:root:Trial 15 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/15/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-15\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-15 for trial-id 15\n",
      "INFO:sagemaker_tune.tuner:(trial 15) - scheduled config {'epochs': 30, 'lr': 7.170865384238529e-05, 'momentum': 0.8825415159505524, 'dropout_rate': 0.051994157891957805}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[16: random]\n",
      "lr: 0.0005844682340160739\n",
      "momentum: 0.9216094164455726\n",
      "dropout_rate: 2.0965565639162103e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16 starts (first milestone = 1)\n",
      "INFO:root:Trial 16 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/16/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-16\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-16 for trial-id 16\n",
      "INFO:sagemaker_tune.tuner:(trial 16) - scheduled config {'epochs': 30, 'lr': 0.0005844682340160739, 'momentum': 0.9216094164455726, 'dropout_rate': 2.0965565639162103e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[17: random]\n",
      "lr: 0.0058361464219496215\n",
      "momentum: 0.8042826781904785\n",
      "dropout_rate: 0.032050077519369696\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 17 starts (first milestone = 1)\n",
      "INFO:root:Trial 17 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/17/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-17\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-17 for trial-id 17\n",
      "INFO:sagemaker_tune.tuner:(trial 17) - scheduled config {'epochs': 30, 'lr': 0.0058361464219496215, 'momentum': 0.8042826781904785, 'dropout_rate': 0.032050077519369696}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[18: random]\n",
      "lr: 0.07448219466020152\n",
      "momentum: 0.8260938102767257\n",
      "dropout_rate: 0.0058390401213138715\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 18 starts (first milestone = 1)\n",
      "INFO:root:Trial 18 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/18/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-18\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-18 for trial-id 18\n",
      "INFO:sagemaker_tune.tuner:(trial 18) - scheduled config {'epochs': 30, 'lr': 0.07448219466020152, 'momentum': 0.8260938102767257, 'dropout_rate': 0.0058390401213138715}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[19: random]\n",
      "lr: 8.908462998397117e-05\n",
      "momentum: 0.9759014209151049\n",
      "dropout_rate: 0.06725702165259029\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 19 starts (first milestone = 1)\n",
      "INFO:root:Trial 19 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/19/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-19\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-19 for trial-id 19\n",
      "INFO:sagemaker_tune.tuner:(trial 19) - scheduled config {'epochs': 30, 'lr': 8.908462998397117e-05, 'momentum': 0.9759014209151049, 'dropout_rate': 0.06725702165259029}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[20: random]\n",
      "lr: 0.0002628989778421065\n",
      "momentum: 0.9054296630076031\n",
      "dropout_rate: 0.0005283658489455272\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 20 starts (first milestone = 1)\n",
      "INFO:root:Trial 20 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/20/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-20\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-20 for trial-id 20\n",
      "INFO:sagemaker_tune.tuner:(trial 20) - scheduled config {'epochs': 30, 'lr': 0.0002628989778421065, 'momentum': 0.9054296630076031, 'dropout_rate': 0.0005283658489455272}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[21: random]\n",
      "lr: 8.08449855632474e-05\n",
      "momentum: 0.8688439943518913\n",
      "dropout_rate: 0.06498221080953084\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 21 starts (first milestone = 1)\n",
      "INFO:root:Trial 21 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/21/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-21\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-21 for trial-id 21\n",
      "INFO:sagemaker_tune.tuner:(trial 21) - scheduled config {'epochs': 30, 'lr': 8.08449855632474e-05, 'momentum': 0.8688439943518913, 'dropout_rate': 0.06498221080953084}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[22: random]\n",
      "lr: 0.0050391367207040004\n",
      "momentum: 0.8055475239666586\n",
      "dropout_rate: 2.3759691995836396e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 22 starts (first milestone = 1)\n",
      "INFO:root:Trial 22 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/22/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-22\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-22 for trial-id 22\n",
      "INFO:sagemaker_tune.tuner:(trial 22) - scheduled config {'epochs': 30, 'lr': 0.0050391367207040004, 'momentum': 0.8055475239666586, 'dropout_rate': 2.3759691995836396e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[23: random]\n",
      "lr: 4.1033499924809827e-05\n",
      "momentum: 0.8496706928287091\n",
      "dropout_rate: 0.00018683165852046644\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 23 starts (first milestone = 1)\n",
      "INFO:root:Trial 23 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/23/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-23\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-23 for trial-id 23\n",
      "INFO:sagemaker_tune.tuner:(trial 23) - scheduled config {'epochs': 30, 'lr': 4.1033499924809827e-05, 'momentum': 0.8496706928287091, 'dropout_rate': 0.00018683165852046644}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      "0 trials running, 0 finished (0 until the end), 39.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 75.81s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 110.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 145.87s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 180.83s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 215.71s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 250.45s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 286.35s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 322.49s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum\n",
      "        4  InProgress     0      0.000720      30  0.001350  0.897261\n",
      "        5  InProgress     0      0.064826      30  0.044987  0.989708\n",
      "        6  InProgress     0      0.000048      30  0.000100  0.981558\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841\n",
      "        8  InProgress     0      0.016232      30  0.000018  0.907014\n",
      "        9  InProgress     0      0.006161      30  0.000070  0.996930\n",
      "       10  InProgress     0      0.001312      30  0.000064  0.817252\n",
      "       11  InProgress     0      0.030247      30  0.000765  0.800684\n",
      "       12  InProgress     0      0.000017      30  0.039436  0.951627\n",
      "       13  InProgress     0      0.000350      30  0.000026  0.977294\n",
      "       14  InProgress     0      0.147869      30  0.018400  0.897408\n",
      "       15  InProgress     0      0.051994      30  0.000072  0.882542\n",
      "       16  InProgress     0      0.000021      30  0.000584  0.921609\n",
      "       17  InProgress     0      0.032050      30  0.005836  0.804283\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671\n",
      "20 trials running, 0 finished (0 until the end), 354.86s wallclock-time\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 14: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 14:1: metric = 0.187\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 4:1: metric = 0.455\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 9: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 9:1: metric = 0.431\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 9 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-9)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 5: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 5:1: metric = 0.098\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 5 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-5)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 15: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 15:1: metric = 0.197\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 15 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-15)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 8: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 8:1: metric = 0.100\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 8 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-8)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[24: random]\n",
      "lr: 0.0019675392057822098\n",
      "momentum: 0.9460183085795278\n",
      "dropout_rate: 5.4537472616405616e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 24 starts (first milestone = 1)\n",
      "INFO:root:Trial 24 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/24/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-24\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-24 for trial-id 24\n",
      "INFO:sagemaker_tune.tuner:(trial 24) - scheduled config {'epochs': 30, 'lr': 0.0019675392057822098, 'momentum': 0.9460183085795278, 'dropout_rate': 5.4537472616405616e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[25: random]\n",
      "lr: 2.959137467413444e-05\n",
      "momentum: 0.8960597367750693\n",
      "dropout_rate: 0.8613884548376707\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 25 starts (first milestone = 1)\n",
      "INFO:root:Trial 25 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/25/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-25\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-25 for trial-id 25\n",
      "INFO:sagemaker_tune.tuner:(trial 25) - scheduled config {'epochs': 30, 'lr': 2.959137467413444e-05, 'momentum': 0.8960597367750693, 'dropout_rate': 0.8613884548376707}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[26: random]\n",
      "lr: 0.00024557773053842356\n",
      "momentum: 0.8124316782794508\n",
      "dropout_rate: 0.7443471721628161\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 26 starts (first milestone = 1)\n",
      "INFO:root:Trial 26 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/26/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-26\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-26 for trial-id 26\n",
      "INFO:sagemaker_tune.tuner:(trial 26) - scheduled config {'epochs': 30, 'lr': 0.00024557773053842356, 'momentum': 0.8124316782794508, 'dropout_rate': 0.7443471721628161}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[27: random]\n",
      "lr: 0.01626381786663239\n",
      "momentum: 0.8180658673097463\n",
      "dropout_rate: 0.0017683101548727025\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 27 starts (first milestone = 1)\n",
      "INFO:root:Trial 27 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/27/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-27\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-27 for trial-id 27\n",
      "INFO:sagemaker_tune.tuner:(trial 27) - scheduled config {'epochs': 30, 'lr': 0.01626381786663239, 'momentum': 0.8180658673097463, 'dropout_rate': 0.0017683101548727025}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 12: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 12:1: metric = 0.101\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 12 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-12)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 17: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 17:1: metric = 0.461\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 6: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 6:1: metric = 0.425\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 6 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-6)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 11: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 11:1: metric = 0.356\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 11 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-11)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 16:1: metric = 0.440\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 10: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 10:1: metric = 0.121\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 10 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-10)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 13: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 13:1: metric = 0.232\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 13 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-13)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[28: random]\n",
      "lr: 0.0001409386990772629\n",
      "momentum: 0.9072990101831133\n",
      "dropout_rate: 0.00043023781904419334\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 28 starts (first milestone = 1)\n",
      "INFO:root:Trial 28 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/28/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-28\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-28 for trial-id 28\n",
      "INFO:sagemaker_tune.tuner:(trial 28) - scheduled config {'epochs': 30, 'lr': 0.0001409386990772629, 'momentum': 0.9072990101831133, 'dropout_rate': 0.00043023781904419334}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[29: random]\n",
      "lr: 0.002064547288607941\n",
      "momentum: 0.9687727825464182\n",
      "dropout_rate: 0.0015848978820512114\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 29 starts (first milestone = 1)\n",
      "INFO:root:Trial 29 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/29/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-29\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-29 for trial-id 29\n",
      "INFO:sagemaker_tune.tuner:(trial 29) - scheduled config {'epochs': 30, 'lr': 0.002064547288607941, 'momentum': 0.9687727825464182, 'dropout_rate': 0.0015848978820512114}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[30: random]\n",
      "lr: 0.00453672919796385\n",
      "momentum: 0.9294805108871467\n",
      "dropout_rate: 0.009086977662763432\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 30 starts (first milestone = 1)\n",
      "INFO:root:Trial 30 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/30/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-30\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-30 for trial-id 30\n",
      "INFO:sagemaker_tune.tuner:(trial 30) - scheduled config {'epochs': 30, 'lr': 0.00453672919796385, 'momentum': 0.9294805108871467, 'dropout_rate': 0.009086977662763432}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[31: random]\n",
      "lr: 2.0573212266644075e-05\n",
      "momentum: 0.860703964122998\n",
      "dropout_rate: 0.07689171710111307\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 31 starts (first milestone = 1)\n",
      "INFO:root:Trial 31 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/31/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-31\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-31 for trial-id 31\n",
      "INFO:sagemaker_tune.tuner:(trial 31) - scheduled config {'epochs': 30, 'lr': 2.0573212266644075e-05, 'momentum': 0.860703964122998, 'dropout_rate': 0.07689171710111307}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[32: random]\n",
      "lr: 8.300746075854551e-05\n",
      "momentum: 0.8164375409083849\n",
      "dropout_rate: 8.52630883773883e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 32 starts (first milestone = 1)\n",
      "INFO:root:Trial 32 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/32/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-32\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-32 for trial-id 32\n",
      "INFO:sagemaker_tune.tuner:(trial 32) - scheduled config {'epochs': 30, 'lr': 8.300746075854551e-05, 'momentum': 0.8164375409083849, 'dropout_rate': 8.52630883773883e-05}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     1      0.000720      30  0.001350  0.897261    1.0   0.4547         50.0     0.010222\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     0      0.003130      30  0.043957  0.951841      -        -            -            -\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     1      0.147869      30  0.018400  0.897408    1.0   0.1870         50.0     0.010222\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     1      0.000021      30  0.000584  0.921609    1.0   0.4401         49.0     0.010018\n",
      "       17  InProgress     1      0.032050      30  0.005836  0.804283    1.0   0.4614         50.0     0.010222\n",
      "       18  InProgress     0      0.005839      30  0.074482  0.826094      -        -            -            -\n",
      "       19  InProgress     0      0.067257      30  0.000089  0.975901      -        -            -            -\n",
      "       20  InProgress     0      0.000528      30  0.000263  0.905430      -        -            -            -\n",
      "       21  InProgress     0      0.064982      30  0.000081  0.868844      -        -            -            -\n",
      "       22  InProgress     0      0.000024      30  0.005039  0.805548      -        -            -            -\n",
      "       23  InProgress     0      0.000187      30  0.000041  0.849671      -        -            -            -\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "24 trials running, 0 finished (0 until the end), 398.18s wallclock-time, 0.13554666666666662$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 21: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 21:1: metric = 0.172\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 21 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-21)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 18: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 18:1: metric = 0.099\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 18 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-18)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 22: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 22:1: metric = 0.444\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 23: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 23:1: metric = 0.127\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 23 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-23)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[33: random]\n",
      "lr: 2.81838414704107e-05\n",
      "momentum: 0.9300166187877263\n",
      "dropout_rate: 0.03385455091158066\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 33 starts (first milestone = 1)\n",
      "INFO:root:Trial 33 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/33/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-33\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-33 for trial-id 33\n",
      "INFO:sagemaker_tune.tuner:(trial 33) - scheduled config {'epochs': 30, 'lr': 2.81838414704107e-05, 'momentum': 0.9300166187877263, 'dropout_rate': 0.03385455091158066}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[34: random]\n",
      "lr: 0.00017000178924922492\n",
      "momentum: 0.8228042008989299\n",
      "dropout_rate: 0.35022071888535955\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 34 starts (first milestone = 1)\n",
      "INFO:root:Trial 34 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/34/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-34\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-34 for trial-id 34\n",
      "INFO:sagemaker_tune.tuner:(trial 34) - scheduled config {'epochs': 30, 'lr': 0.00017000178924922492, 'momentum': 0.8228042008989299, 'dropout_rate': 0.35022071888535955}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[35: random]\n",
      "lr: 0.0038795758893581853\n",
      "momentum: 0.9321743067800273\n",
      "dropout_rate: 0.17000286865976716\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 35 starts (first milestone = 1)\n",
      "INFO:root:Trial 35 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/35/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-35\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-35 for trial-id 35\n",
      "INFO:sagemaker_tune.tuner:(trial 35) - scheduled config {'epochs': 30, 'lr': 0.0038795758893581853, 'momentum': 0.9321743067800273, 'dropout_rate': 0.17000286865976716}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 20: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 20:1: metric = 0.306\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 20 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-20)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 7: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 7:1: metric = 0.099\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 7 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-7)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[36: random]\n",
      "lr: 0.001171784532144289\n",
      "momentum: 0.867490526479073\n",
      "dropout_rate: 2.083674715056381e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 36 starts (first milestone = 1)\n",
      "INFO:root:Trial 36 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/36/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-36\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-36 for trial-id 36\n",
      "INFO:sagemaker_tune.tuner:(trial 36) - scheduled config {'epochs': 30, 'lr': 0.001171784532144289, 'momentum': 0.867490526479073, 'dropout_rate': 2.083674715056381e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[37: random]\n",
      "lr: 0.005568579991690971\n",
      "momentum: 0.8034179975450513\n",
      "dropout_rate: 0.581935685810846\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 37 starts (first milestone = 1)\n",
      "INFO:root:Trial 37 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/37/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-37\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-37 for trial-id 37\n",
      "INFO:sagemaker_tune.tuner:(trial 37) - scheduled config {'epochs': 30, 'lr': 0.005568579991690971, 'momentum': 0.8034179975450513, 'dropout_rate': 0.581935685810846}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 19: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 19:1: metric = 0.379\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     2      0.000720      30  0.001350  0.897261    2.0   0.5483         91.0     0.018604\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     2      0.147869      30  0.018400  0.897408    2.0   0.2051         90.0     0.018400\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     2      0.000021      30  0.000584  0.921609    2.0   0.5367         90.0     0.018400\n",
      "       17  InProgress     2      0.032050      30  0.005836  0.804283    2.0   0.5136         91.0     0.018604\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     1      0.067257      30  0.000089  0.975901    1.0   0.3790         53.0     0.010836\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     1      0.000024      30  0.005039  0.805548    1.0   0.4437         49.0     0.010018\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "34 trials running, 0 finished (0 until the end), 433.82s wallclock-time, 0.24328888888888883$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 14: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 14:3: metric = 0.186\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 4:3: metric = 0.557\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 17: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 17:3: metric = 0.494\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 17 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-17)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 16:3: metric = 0.550\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[38: random]\n",
      "lr: 0.02156515957061452\n",
      "momentum: 0.9730176983149593\n",
      "dropout_rate: 0.01581787026842719\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 38 starts (first milestone = 1)\n",
      "INFO:root:Trial 38 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/38/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-38\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-38 for trial-id 38\n",
      "INFO:sagemaker_tune.tuner:(trial 38) - scheduled config {'epochs': 30, 'lr': 0.02156515957061452, 'momentum': 0.9730176983149593, 'dropout_rate': 0.01581787026842719}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     3      0.000720      30  0.001350  0.897261    3.0   0.5573        131.0     0.026782\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     3      0.147869      30  0.018400  0.897408    3.0   0.2051        131.0     0.026782\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     3      0.000021      30  0.000584  0.921609    3.0   0.5496        131.0     0.026782\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     2      0.067257      30  0.000089  0.975901    2.0   0.4696         94.0     0.019218\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     2      0.000024      30  0.005039  0.805548    2.0   0.5293         91.0     0.018604\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "35 trials running, 0 finished (0 until the end), 471.33s wallclock-time, 0.29337777777777774$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 22: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 22:3: metric = 0.534\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 22 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-22)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[39: random]\n",
      "lr: 0.00019304591289035771\n",
      "momentum: 0.9322781532776181\n",
      "dropout_rate: 8.902133600897866e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 39 starts (first milestone = 1)\n",
      "INFO:root:Trial 39 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/39/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-39\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-39 for trial-id 39\n",
      "INFO:sagemaker_tune.tuner:(trial 39) - scheduled config {'epochs': 30, 'lr': 0.00019304591289035771, 'momentum': 0.9322781532776181, 'dropout_rate': 8.902133600897866e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 19: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 19:3: metric = 0.515\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 19 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-19)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[40: random]\n",
      "lr: 0.03209228675348288\n",
      "momentum: 0.9954162659862049\n",
      "dropout_rate: 0.0001180818774174168\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 40 starts (first milestone = 1)\n",
      "INFO:root:Trial 40 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/40/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-40\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-40 for trial-id 40\n",
      "INFO:sagemaker_tune.tuner:(trial 40) - scheduled config {'epochs': 30, 'lr': 0.03209228675348288, 'momentum': 0.9954162659862049, 'dropout_rate': 0.0001180818774174168}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     4      0.000720      30  0.001350  0.897261    4.0   0.5841        173.0     0.035369\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     4      0.147869      30  0.018400  0.897408    4.0   0.2051        172.0     0.035164\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     4      0.000021      30  0.000584  0.921609    4.0   0.5947        171.0     0.034960\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 508.16s wallclock-time, 0.33528888888888886$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     5      0.000720      30  0.001350  0.897261    5.0   0.5898        214.0     0.043751\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     5      0.147869      30  0.018400  0.897408    5.0   0.2051        213.0     0.043547\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     4      0.000021      30  0.000584  0.921609    4.0   0.5947        171.0     0.034960\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 539.19s wallclock-time, 0.35205333333333333$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     5      0.000720      30  0.001350  0.897261    5.0   0.5898        214.0     0.043751\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     5      0.147869      30  0.018400  0.897408    5.0   0.2051        213.0     0.043547\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     5      0.000021      30  0.000584  0.921609    5.0   0.5986        212.0     0.043342\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 570.42s wallclock-time, 0.36043555555555556$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     6      0.000720      30  0.001350  0.897261    6.0   0.5902        254.0     0.051929\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     6      0.147869      30  0.018400  0.897408    6.0   0.2108        254.0     0.051929\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     6      0.000021      30  0.000584  0.921609    6.0   0.6007        253.0     0.051724\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 601.71s wallclock-time, 0.38537777777777776$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     7      0.000720      30  0.001350  0.897261    7.0   0.6158        295.0     0.060311\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     7      0.147869      30  0.018400  0.897408    7.0   0.2108        295.0     0.060311\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     7      0.000021      30  0.000584  0.921609    7.0   0.6087        294.0     0.060107\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 632.75s wallclock-time, 0.41052444444444447$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     8      0.000720      30  0.001350  0.897261    8.0   0.6158        337.0     0.068898\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     8      0.147869      30  0.018400  0.897408    8.0   0.2108        336.0     0.068693\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     7      0.000021      30  0.000584  0.921609    7.0   0.6087        294.0     0.060107\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 666.84s wallclock-time, 0.42749333333333334$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 14: Reaches 9, continues to 27\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 14:9: metric = 0.097\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 4: Reaches 9, continues to 27\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 4:9: metric = 0.610\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress     9      0.000720      30  0.001350  0.897261    9.0   0.6158        377.0     0.077076\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress     9      0.147869      30  0.018400  0.897408    9.0   0.2108        377.0     0.077076\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     8      0.000021      30  0.000584  0.921609    8.0   0.6087        334.0     0.068284\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "37 trials running, 0 finished (0 until the end), 704.61s wallclock-time, 0.45223111111111114$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 16: Terminating evaluation at 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 16:9: metric = 0.601\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 16 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-16)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[41: random]\n",
      "lr: 0.07089197753179541\n",
      "momentum: 0.8049729857278806\n",
      "dropout_rate: 0.002612843262532225\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 41 starts (first milestone = 1)\n",
      "INFO:root:Trial 41 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/41/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-41\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-41 for trial-id 41\n",
      "INFO:sagemaker_tune.tuner:(trial 41) - scheduled config {'epochs': 30, 'lr': 0.07089197753179541, 'momentum': 0.8049729857278806, 'dropout_rate': 0.002612843262532225}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    10      0.000720      30  0.001350  0.897261   10.0   0.6158        419.0     0.085662\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    10      0.147869      30  0.018400  0.897408   10.0   0.2108        418.0     0.085458\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     0      0.000055      30  0.001968  0.946018      -        -            -            -\n",
      "       25  InProgress     0      0.861388      30  0.000030  0.896060      -        -            -            -\n",
      "       26  InProgress     0      0.744347      30  0.000246  0.812432      -        -            -            -\n",
      "       27  InProgress     0      0.001768      30  0.016264  0.818066      -        -            -            -\n",
      "       28  InProgress     0      0.000430      30  0.000141  0.907299      -        -            -            -\n",
      "       29  InProgress     0      0.001585      30  0.002065  0.968773      -        -            -            -\n",
      "       30  InProgress     0      0.009087      30  0.004537  0.929481      -        -            -            -\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     0      0.000085      30  0.000083  0.816438      -        -            -            -\n",
      "       33  InProgress     0      0.033855      30  0.000028  0.930017      -        -            -            -\n",
      "       34  InProgress     0      0.350221      30  0.000170  0.822804      -        -            -            -\n",
      "       35  InProgress     0      0.170003      30  0.003880  0.932174      -        -            -            -\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     0      0.581936      30  0.005569  0.803418      -        -            -            -\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "38 trials running, 0 finished (0 until the end), 747.51s wallclock-time, 0.47758222222222224$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 24: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 24:1: metric = 0.444\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 25: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 25:1: metric = 0.102\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 25 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-25)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 26: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 26:1: metric = 0.152\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 26 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-26)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 32: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 32:1: metric = 0.149\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 32 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-32)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 28: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 28:1: metric = 0.251\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 28 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-28)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 34: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 34:1: metric = 0.152\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 34 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-34)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 29: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 29:1: metric = 0.367\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[42: random]\n",
      "lr: 0.004072990166072525\n",
      "momentum: 0.8258941319405891\n",
      "dropout_rate: 0.008146875592618235\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 42 starts (first milestone = 1)\n",
      "INFO:root:Trial 42 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/42/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-42\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-42 for trial-id 42\n",
      "INFO:sagemaker_tune.tuner:(trial 42) - scheduled config {'epochs': 30, 'lr': 0.004072990166072525, 'momentum': 0.8258941319405891, 'dropout_rate': 0.008146875592618235}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[43: random]\n",
      "lr: 0.014953658020079277\n",
      "momentum: 0.8161388551489323\n",
      "dropout_rate: 0.008963760247854826\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 43 starts (first milestone = 1)\n",
      "INFO:root:Trial 43 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/43/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-43\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-43 for trial-id 43\n",
      "INFO:sagemaker_tune.tuner:(trial 43) - scheduled config {'epochs': 30, 'lr': 0.014953658020079277, 'momentum': 0.8161388551489323, 'dropout_rate': 0.008963760247854826}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[44: random]\n",
      "lr: 0.09409892208256317\n",
      "momentum: 0.8947750633311913\n",
      "dropout_rate: 0.00020240252063587796\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 44 starts (first milestone = 1)\n",
      "INFO:root:Trial 44 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/44/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-44\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-44 for trial-id 44\n",
      "INFO:sagemaker_tune.tuner:(trial 44) - scheduled config {'epochs': 30, 'lr': 0.09409892208256317, 'momentum': 0.8947750633311913, 'dropout_rate': 0.00020240252063587796}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[45: random]\n",
      "lr: 0.07903713559733017\n",
      "momentum: 0.842937070114111\n",
      "dropout_rate: 0.017016120541420963\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 45 starts (first milestone = 1)\n",
      "INFO:root:Trial 45 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/45/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-45\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-45 for trial-id 45\n",
      "INFO:sagemaker_tune.tuner:(trial 45) - scheduled config {'epochs': 30, 'lr': 0.07903713559733017, 'momentum': 0.842937070114111, 'dropout_rate': 0.017016120541420963}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[46: random]\n",
      "lr: 0.0015953646818209822\n",
      "momentum: 0.9943851412379143\n",
      "dropout_rate: 0.00011407058718770725\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 46 starts (first milestone = 1)\n",
      "INFO:root:Trial 46 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/46/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-46\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-46 for trial-id 46\n",
      "INFO:sagemaker_tune.tuner:(trial 46) - scheduled config {'epochs': 30, 'lr': 0.0015953646818209822, 'momentum': 0.9943851412379143, 'dropout_rate': 0.00011407058718770725}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 33: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 33:1: metric = 0.134\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 33 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-33)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 27: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 27:1: metric = 0.247\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 27 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-27)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 30: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 30:1: metric = 0.361\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 37: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 37:1: metric = 0.430\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 35: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 35:1: metric = 0.365\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[47: random]\n",
      "lr: 0.00048763167205735604\n",
      "momentum: 0.9229750754790993\n",
      "dropout_rate: 0.001789827305142929\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 47 starts (first milestone = 1)\n",
      "INFO:root:Trial 47 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/47/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-47\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-47 for trial-id 47\n",
      "INFO:sagemaker_tune.tuner:(trial 47) - scheduled config {'epochs': 30, 'lr': 0.00048763167205735604, 'momentum': 0.9229750754790993, 'dropout_rate': 0.001789827305142929}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[48: random]\n",
      "lr: 0.0028669476395371805\n",
      "momentum: 0.8164372845034971\n",
      "dropout_rate: 0.0010654171894416233\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 48 starts (first milestone = 1)\n",
      "INFO:root:Trial 48 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/48/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-48\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-48 for trial-id 48\n",
      "INFO:sagemaker_tune.tuner:(trial 48) - scheduled config {'epochs': 30, 'lr': 0.0028669476395371805, 'momentum': 0.8164372845034971, 'dropout_rate': 0.0010654171894416233}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    11      0.000720      30  0.001350  0.897261   11.0   0.6158        460.0     0.094044\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    11      0.147869      30  0.018400  0.897408   11.0   0.2108        459.0     0.093840\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     1      0.000055      30  0.001968  0.946018    1.0   0.4438         52.0     0.010631\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     1      0.001585      30  0.002065  0.968773    1.0   0.3667         49.0     0.010018\n",
      "       30  InProgress     1      0.009087      30  0.004537  0.929481    1.0   0.3615         54.0     0.011040\n",
      "       31  InProgress     0      0.076892      30  0.000021  0.860704      -        -            -            -\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     1      0.170003      30  0.003880  0.932174    1.0   0.3646         53.0     0.010836\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     1      0.581936      30  0.005569  0.803418    1.0   0.4304         50.0     0.010222\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "43 trials running, 0 finished (0 until the end), 781.49s wallclock-time, 0.6190577777777782$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 31: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 31:1: metric = 0.099\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 31 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-31)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[49: random]\n",
      "lr: 0.0004363498629844251\n",
      "momentum: 0.8301195874752494\n",
      "dropout_rate: 0.7495707768119495\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 49 starts (first milestone = 1)\n",
      "INFO:root:Trial 49 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/49/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-49\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-49 for trial-id 49\n",
      "INFO:sagemaker_tune.tuner:(trial 49) - scheduled config {'epochs': 30, 'lr': 0.0004363498629844251, 'momentum': 0.8301195874752494, 'dropout_rate': 0.7495707768119495}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    12      0.000720      30  0.001350  0.897261   12.0   0.6158        500.0     0.102222\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    12      0.147869      30  0.018400  0.897408   12.0   0.2108        499.0     0.102018\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     2      0.000055      30  0.001968  0.946018    2.0   0.4971         95.0     0.019422\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     2      0.001585      30  0.002065  0.968773    2.0   0.3867         90.0     0.018400\n",
      "       30  InProgress     1      0.009087      30  0.004537  0.929481    1.0   0.3615         54.0     0.011040\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     1      0.170003      30  0.003880  0.932174    1.0   0.3646         53.0     0.010836\n",
      "       36  InProgress     0      0.000021      30  0.001172  0.867491      -        -            -            -\n",
      "       37  InProgress     2      0.581936      30  0.005569  0.803418    2.0   0.4305         91.0     0.018604\n",
      "       38  InProgress     0      0.015818      30  0.021565  0.973018      -        -            -            -\n",
      "       39  InProgress     0      0.000089      30  0.000193  0.932278      -        -            -            -\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "46 trials running, 0 finished (0 until the end), 818.89s wallclock-time, 0.6718044444444448$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 38: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 38:1: metric = 0.106\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 38 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-38)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 36: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 36:1: metric = 0.458\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[50: random]\n",
      "lr: 0.0015084220294283599\n",
      "momentum: 0.8465152053133949\n",
      "dropout_rate: 0.6592493394967819\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 50 starts (first milestone = 1)\n",
      "INFO:root:Trial 50 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/50/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-50\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-50 for trial-id 50\n",
      "INFO:sagemaker_tune.tuner:(trial 50) - scheduled config {'epochs': 30, 'lr': 0.0015084220294283599, 'momentum': 0.8465152053133949, 'dropout_rate': 0.6592493394967819}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 24: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 24:3: metric = 0.505\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 24 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-24)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 39: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 39:1: metric = 0.341\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 39 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-39)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 29: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 29:3: metric = 0.394\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 29 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-29)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[51: random]\n",
      "lr: 4.9868497383419015e-05\n",
      "momentum: 0.8398968577662485\n",
      "dropout_rate: 0.00041745429506822934\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 51 starts (first milestone = 1)\n",
      "INFO:root:Trial 51 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/51/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-51\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-51 for trial-id 51\n",
      "INFO:sagemaker_tune.tuner:(trial 51) - scheduled config {'epochs': 30, 'lr': 4.9868497383419015e-05, 'momentum': 0.8398968577662485, 'dropout_rate': 0.00041745429506822934}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[52: random]\n",
      "lr: 0.0004767719792783992\n",
      "momentum: 0.9120416746636769\n",
      "dropout_rate: 1.259773870022041e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 52 starts (first milestone = 1)\n",
      "INFO:root:Trial 52 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/52/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-52\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-52 for trial-id 52\n",
      "INFO:sagemaker_tune.tuner:(trial 52) - scheduled config {'epochs': 30, 'lr': 0.0004767719792783992, 'momentum': 0.9120416746636769, 'dropout_rate': 1.259773870022041e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[53: random]\n",
      "lr: 0.06230777838358934\n",
      "momentum: 0.9067288778630651\n",
      "dropout_rate: 0.9108940578351917\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 53 starts (first milestone = 1)\n",
      "INFO:root:Trial 53 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/53/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-53\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-53 for trial-id 53\n",
      "INFO:sagemaker_tune.tuner:(trial 53) - scheduled config {'epochs': 30, 'lr': 0.06230777838358934, 'momentum': 0.9067288778630651, 'dropout_rate': 0.9108940578351917}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 37: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 37:3: metric = 0.480\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 37 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-37)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[54: random]\n",
      "lr: 7.724233841309926e-05\n",
      "momentum: 0.8250279455769709\n",
      "dropout_rate: 0.11506361575506133\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 54 starts (first milestone = 1)\n",
      "INFO:root:Trial 54 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/54/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-54\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-54 for trial-id 54\n",
      "INFO:sagemaker_tune.tuner:(trial 54) - scheduled config {'epochs': 30, 'lr': 7.724233841309926e-05, 'momentum': 0.8250279455769709, 'dropout_rate': 0.11506361575506133}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    12      0.000720      30  0.001350  0.897261   12.0   0.6158        500.0     0.102222\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    13      0.147869      30  0.018400  0.897408   13.0   0.2108        540.0     0.110400\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     2      0.009087      30  0.004537  0.929481    2.0   0.3615         98.0     0.020036\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     2      0.170003      30  0.003880  0.932174    2.0   0.3646         95.0     0.019422\n",
      "       36  InProgress     1      0.000021      30  0.001172  0.867491    1.0   0.4583         52.0     0.010631\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     0      0.000118      30  0.032092  0.995416      -        -            -            -\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "50 trials running, 0 finished (0 until the end), 853.49s wallclock-time, 0.7548088888888893$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 30: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 30:3: metric = 0.365\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 30 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-30)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[55: random]\n",
      "lr: 0.01226731916719318\n",
      "momentum: 0.993875995401898\n",
      "dropout_rate: 1.8427378627325783e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 55 starts (first milestone = 1)\n",
      "INFO:root:Trial 55 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/55/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-55\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-55 for trial-id 55\n",
      "INFO:sagemaker_tune.tuner:(trial 55) - scheduled config {'epochs': 30, 'lr': 0.01226731916719318, 'momentum': 0.993875995401898, 'dropout_rate': 1.8427378627325783e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 40: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 40:1: metric = 0.103\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 40 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-40)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 35: Terminating evaluation at 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 35:3: metric = 0.345\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 35 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-35)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[56: random]\n",
      "lr: 0.00015292374077796305\n",
      "momentum: 0.9063273436098077\n",
      "dropout_rate: 0.013483819872995665\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 56 starts (first milestone = 1)\n",
      "INFO:root:Trial 56 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/56/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-56\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-56 for trial-id 56\n",
      "INFO:sagemaker_tune.tuner:(trial 56) - scheduled config {'epochs': 30, 'lr': 0.00015292374077796305, 'momentum': 0.9063273436098077, 'dropout_rate': 0.013483819872995665}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[57: random]\n",
      "lr: 0.02068470239493174\n",
      "momentum: 0.964167689235939\n",
      "dropout_rate: 0.7729575210111527\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 57 starts (first milestone = 1)\n",
      "INFO:root:Trial 57 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/57/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-57\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-57 for trial-id 57\n",
      "INFO:sagemaker_tune.tuner:(trial 57) - scheduled config {'epochs': 30, 'lr': 0.02068470239493174, 'momentum': 0.964167689235939, 'dropout_rate': 0.7729575210111527}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    14      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    13      0.147869      30  0.018400  0.897408   13.0   0.2108        540.0     0.110400\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     2      0.000021      30  0.001172  0.867491    2.0   0.5277         96.0     0.019627\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "54 trials running, 0 finished (0 until the end), 887.25s wallclock-time, 0.8006044444444449$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 36: Reaches 3, continues to 9\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 36:3: metric = 0.569\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    16      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    14      0.147869      30  0.018400  0.897408   14.0   0.2108        581.0     0.118782\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     3      0.000021      30  0.001172  0.867491    3.0   0.5690        140.0     0.028622\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "54 trials running, 0 finished (0 until the end), 919.01s wallclock-time, 0.8179822222222226$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    18      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    15      0.147869      30  0.018400  0.897408   15.0   0.2108        622.0     0.127164\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     3      0.000021      30  0.001172  0.867491    3.0   0.5690        140.0     0.028622\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "54 trials running, 0 finished (0 until the end), 950.62s wallclock-time, 0.8263644444444449$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    19      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    16      0.147869      30  0.018400  0.897408   16.0   0.2108        663.0     0.135547\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     4      0.000021      30  0.001172  0.867491    4.0   0.5806        184.0     0.037618\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "54 trials running, 0 finished (0 until the end), 982.71s wallclock-time, 0.8437422222222227$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    20      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    16      0.147869      30  0.018400  0.897408   16.0   0.2108        663.0     0.135547\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     5      0.000021      30  0.001172  0.867491    5.0   0.6048        228.0     0.046613\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "54 trials running, 0 finished (0 until the end), 1016.88s wallclock-time, 0.8527377777777783$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    22      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    17      0.147869      30  0.018400  0.897408   17.0   0.2108        704.0     0.143929\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     6      0.000021      30  0.001172  0.867491    6.0   0.6184        270.0     0.055200\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     0      0.002613      30  0.070892  0.804973      -        -            -            -\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "54 trials running, 0 finished (0 until the end), 1049.81s wallclock-time, 0.8697066666666672$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 41: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 41:1: metric = 0.104\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 41 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-41)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[58: random]\n",
      "lr: 0.000411119384003574\n",
      "momentum: 0.9147263442496137\n",
      "dropout_rate: 0.04413148479077458\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 58 starts (first milestone = 1)\n",
      "INFO:root:Trial 58 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/58/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-58\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-58 for trial-id 58\n",
      "INFO:sagemaker_tune.tuner:(trial 58) - scheduled config {'epochs': 30, 'lr': 0.000411119384003574, 'momentum': 0.9147263442496137, 'dropout_rate': 0.04413148479077458}\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    25      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    18      0.147869      30  0.018400  0.897408   18.0   0.2108        745.0     0.152311\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     7      0.000021      30  0.001172  0.867491    7.0   0.6184        314.0     0.064196\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     1      0.002613      30  0.070892  0.804973    1.0   0.1042         51.0     0.010427\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "       58  InProgress     0      0.044131      30  0.000411  0.914726      -        -            -            -\n",
      "55 trials running, 0 finished (0 until the end), 1088.87s wallclock-time, 0.8975111111111116$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    28      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    19      0.147869      30  0.018400  0.897408   19.0   0.2108        786.0     0.160693\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     7      0.000021      30  0.001172  0.867491    7.0   0.6184        314.0     0.064196\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     1      0.002613      30  0.070892  0.804973    1.0   0.1042         51.0     0.010427\n",
      "       42  InProgress     0      0.008147      30  0.004073  0.825894      -        -            -            -\n",
      "       43  InProgress     0      0.008964      30  0.014954  0.816139      -        -            -            -\n",
      "       44  InProgress     0      0.000202      30  0.094099  0.894775      -        -            -            -\n",
      "       45  InProgress     0      0.017016      30  0.079037  0.842937      -        -            -            -\n",
      "       46  InProgress     0      0.000114      30  0.001595  0.994385      -        -            -            -\n",
      "       47  InProgress     0      0.001790      30  0.000488  0.922975      -        -            -            -\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "       58  InProgress     0      0.044131      30  0.000411  0.914726      -        -            -            -\n",
      "55 trials running, 0 finished (0 until the end), 1122.97s wallclock-time, 0.9058933333333339$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 44: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 44:1: metric = 0.103\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 44 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-44)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 45: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 45:1: metric = 0.101\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 45 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-45)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[59: random]\n",
      "lr: 0.018706440723845752\n",
      "momentum: 0.9726373644940384\n",
      "dropout_rate: 0.2586171205572037\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 59 starts (first milestone = 1)\n",
      "INFO:root:Trial 59 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/59/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-59\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-59 for trial-id 59\n",
      "INFO:sagemaker_tune.tuner:(trial 59) - scheduled config {'epochs': 30, 'lr': 0.018706440723845752, 'momentum': 0.9726373644940384, 'dropout_rate': 0.2586171205572037}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[60: random]\n",
      "lr: 0.00970523728990116\n",
      "momentum: 0.9633347952261391\n",
      "dropout_rate: 0.00205678564391227\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 60 starts (first milestone = 1)\n",
      "INFO:root:Trial 60 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/60/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-60\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-60 for trial-id 60\n",
      "INFO:sagemaker_tune.tuner:(trial 60) - scheduled config {'epochs': 30, 'lr': 0.00970523728990116, 'momentum': 0.9633347952261391, 'dropout_rate': 0.00205678564391227}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 46: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 46:1: metric = 0.100\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 46 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-46)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 43: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 43:1: metric = 0.304\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 43 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-43)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[61: random]\n",
      "lr: 0.0001787599822415302\n",
      "momentum: 0.8468530318076394\n",
      "dropout_rate: 0.041431607874016854\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 61 starts (first milestone = 1)\n",
      "INFO:root:Trial 61 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/61/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-61\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-61 for trial-id 61\n",
      "INFO:sagemaker_tune.tuner:(trial 61) - scheduled config {'epochs': 30, 'lr': 0.0001787599822415302, 'momentum': 0.8468530318076394, 'dropout_rate': 0.041431607874016854}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[62: random]\n",
      "lr: 1.3510279718780329e-05\n",
      "momentum: 0.9115455585018208\n",
      "dropout_rate: 4.975173169988788e-05\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 62 starts (first milestone = 1)\n",
      "INFO:root:Trial 62 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/62/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-62\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-62 for trial-id 62\n",
      "INFO:sagemaker_tune.tuner:(trial 62) - scheduled config {'epochs': 30, 'lr': 1.3510279718780329e-05, 'momentum': 0.9115455585018208, 'dropout_rate': 4.975173169988788e-05}\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 47: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 47:1: metric = 0.435\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 42: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 42:1: metric = 0.431\n",
      "INFO:sagemaker_tune.tuner:tuning status\n",
      " trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
      "        4  InProgress    36      0.000720      30  0.001350  0.897261   13.0   0.6158        542.0     0.110809\n",
      "        5  InProgress     1      0.064826      30  0.044987  0.989708    1.0   0.0983         51.0     0.010427\n",
      "        6  InProgress     1      0.000048      30  0.000100  0.981558    1.0   0.4250         53.0     0.010836\n",
      "        7  InProgress     1      0.003130      30  0.043957  0.951841    1.0   0.0990         60.0     0.012267\n",
      "        8  InProgress     1      0.016232      30  0.000018  0.907014    1.0   0.0999         51.0     0.010427\n",
      "        9  InProgress     1      0.006161      30  0.000070  0.996930    1.0   0.4306         52.0     0.010631\n",
      "       10  InProgress     1      0.001312      30  0.000064  0.817252    1.0   0.1208         52.0     0.010631\n",
      "       11  InProgress     1      0.030247      30  0.000765  0.800684    1.0   0.3560         51.0     0.010427\n",
      "       12  InProgress     1      0.000017      30  0.039436  0.951627    1.0   0.1007         50.0     0.010222\n",
      "       13  InProgress     1      0.000350      30  0.000026  0.977294    1.0   0.2324         54.0     0.011040\n",
      "       14  InProgress    20      0.147869      30  0.018400  0.897408   20.0   0.2108        827.0     0.169076\n",
      "       15  InProgress     1      0.051994      30  0.000072  0.882542    1.0   0.1969         50.0     0.010222\n",
      "       16  InProgress     9      0.000021      30  0.000584  0.921609    9.0   0.6087        375.0     0.076667\n",
      "       17  InProgress     3      0.032050      30  0.005836  0.804283    3.0   0.5136        131.0     0.026782\n",
      "       18  InProgress     1      0.005839      30  0.074482  0.826094    1.0   0.0993         50.0     0.010222\n",
      "       19  InProgress     3      0.067257      30  0.000089  0.975901    3.0   0.5153        135.0     0.027600\n",
      "       20  InProgress     1      0.000528      30  0.000263  0.905430    1.0   0.3056         52.0     0.010631\n",
      "       21  InProgress     1      0.064982      30  0.000081  0.868844    1.0   0.1722         50.0     0.010222\n",
      "       22  InProgress     3      0.000024      30  0.005039  0.805548    3.0   0.5344        132.0     0.026987\n",
      "       23  InProgress     1      0.000187      30  0.000041  0.849671    1.0   0.1271         50.0     0.010222\n",
      "       24  InProgress     3      0.000055      30  0.001968  0.946018    3.0   0.5047        138.0     0.028213\n",
      "       25  InProgress     1      0.861388      30  0.000030  0.896060    1.0   0.1016         54.0     0.011040\n",
      "       26  InProgress     1      0.744347      30  0.000246  0.812432    1.0   0.1521         50.0     0.010222\n",
      "       27  InProgress     1      0.001768      30  0.016264  0.818066    1.0   0.2470         50.0     0.010222\n",
      "       28  InProgress     1      0.000430      30  0.000141  0.907299    1.0   0.2514         49.0     0.010018\n",
      "       29  InProgress     3      0.001585      30  0.002065  0.968773    3.0   0.3939        130.0     0.026578\n",
      "       30  InProgress     3      0.009087      30  0.004537  0.929481    3.0   0.3653        143.0     0.029236\n",
      "       31  InProgress     1      0.076892      30  0.000021  0.860704    1.0   0.0995         53.0     0.010836\n",
      "       32  InProgress     1      0.000085      30  0.000083  0.816438    1.0   0.1487         50.0     0.010222\n",
      "       33  InProgress     1      0.033855      30  0.000028  0.930017    1.0   0.1345         50.0     0.010222\n",
      "       34  InProgress     1      0.350221      30  0.000170  0.822804    1.0   0.1518         49.0     0.010018\n",
      "       35  InProgress     3      0.170003      30  0.003880  0.932174    3.0   0.3646        138.0     0.028213\n",
      "       36  InProgress     8      0.000021      30  0.001172  0.867491    8.0   0.6184        357.0     0.072987\n",
      "       37  InProgress     3      0.581936      30  0.005569  0.803418    3.0   0.4795        132.0     0.026987\n",
      "       38  InProgress     1      0.015818      30  0.021565  0.973018    1.0   0.1062         51.0     0.010427\n",
      "       39  InProgress     1      0.000089      30  0.000193  0.932278    1.0   0.3411         52.0     0.010631\n",
      "       40  InProgress     1      0.000118      30  0.032092  0.995416    1.0   0.1035         50.0     0.010222\n",
      "       41  InProgress     1      0.002613      30  0.070892  0.804973    1.0   0.1042         51.0     0.010427\n",
      "       42  InProgress     1      0.008147      30  0.004073  0.825894    1.0   0.4315         50.0     0.010222\n",
      "       43  InProgress     1      0.008964      30  0.014954  0.816139    1.0   0.3039         50.0     0.010222\n",
      "       44  InProgress     1      0.000202      30  0.094099  0.894775    1.0   0.1030         51.0     0.010427\n",
      "       45  InProgress     1      0.017016      30  0.079037  0.842937    1.0   0.1012         50.0     0.010222\n",
      "       46  InProgress     1      0.000114      30  0.001595  0.994385    1.0   0.0999         52.0     0.010631\n",
      "       47  InProgress     1      0.001790      30  0.000488  0.922975    1.0   0.4348         50.0     0.010222\n",
      "       48  InProgress     0      0.001065      30  0.002867  0.816437      -        -            -            -\n",
      "       49  InProgress     0      0.749571      30  0.000436  0.830120      -        -            -            -\n",
      "       50  InProgress     0      0.659249      30  0.001508  0.846515      -        -            -            -\n",
      "       51  InProgress     0      0.000417      30  0.000050  0.839897      -        -            -            -\n",
      "       52  InProgress     0      0.000013      30  0.000477  0.912042      -        -            -            -\n",
      "       53  InProgress     0      0.910894      30  0.062308  0.906729      -        -            -            -\n",
      "       54  InProgress     0      0.115064      30  0.000077  0.825028      -        -            -            -\n",
      "       55  InProgress     0      0.000018      30  0.012267  0.993876      -        -            -            -\n",
      "       56  InProgress     0      0.013484      30  0.000153  0.906327      -        -            -            -\n",
      "       57  InProgress     0      0.772958      30  0.020685  0.964168      -        -            -            -\n",
      "       58  InProgress     0      0.044131      30  0.000411  0.914726      -        -            -            -\n",
      "       59  InProgress     0      0.258617      30  0.018706  0.972637      -        -            -            -\n",
      "       60  InProgress     0      0.002057      30  0.009705  0.963335      -        -            -            -\n",
      "       61  InProgress     0      0.041432      30  0.000179  0.846853      -        -            -            -\n",
      "       62  InProgress     0      0.000050      30  0.000014  0.911546      -        -            -            -\n",
      "59 trials running, 0 finished (0 until the end), 1156.06s wallclock-time, 0.9850133333333339$ estimated cost\n",
      "\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 48: Reaches 1, continues to 3\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 48:1: metric = 0.449\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 36: Reaches 9, continues to 27\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 36:9: metric = 0.614\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 49: Terminating evaluation at 1\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.searcher:Update for trial_id 49:1: metric = 0.301\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:stopping 49 (cifar10-on-sagemaker-2021-11-05-09-50-26-541-49)\n",
      "INFO:sagemaker_tune.optimizer.schedulers.searchers.bayesopt.utils.debug_log:[63: random]\n",
      "lr: 6.559829802220672e-05\n",
      "momentum: 0.8911822534636371\n",
      "dropout_rate: 0.0001538787651045116\n",
      "INFO:sagemaker_tune.optimizer.schedulers.hyperband:trial_id 63 starts (first milestone = 1)\n",
      "INFO:root:Trial 63 will checkpoint results to s3://sagemaker-us-west-2-760692251996/sagemaker-tune/cifar10-on-sagemaker-2021-11-05-09-50-26-541/63/.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-on-sagemaker-2021-11-05-09-50-26-541-63\n",
      "INFO:sagemaker_tune.backend.sagemaker_backend.sagemaker_backend:scheduled cifar10-on-sagemaker-2021-11-05-09-50-26-541-63 for trial-id 63\n",
      "INFO:sagemaker_tune.tuner:(trial 63) - scheduled config {'epochs': 30, 'lr': 6.559829802220672e-05, 'momentum': 0.8911822534636371, 'dropout_rate': 0.0001538787651045116}\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    backend=backend,\n",
    "    scheduler=scheduler,\n",
    "    stop_criterion=StoppingCriterion(max_wallclock_time=3600, max_cost=20.0),\n",
    "    n_workers=20,\n",
    "    tuner_name=\"cifar10-on-sagemaker\"\n",
    ")\n",
    "\n",
    "tuner.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b20337",
   "metadata": {},
   "source": [
    "After the instance starts their training, you will see the status update as in the local case.\n",
    "An important difference is that the total estimated dollar-cost is displayed as well the cost of workers.\n",
    "\n",
    "\n",
    "```\n",
    "trial_id      status  iter  dropout_rate  epochs        lr  momentum  epoch  val_acc  worker-time  worker-cost\n",
    "        0  InProgress     1      0.003162      30  0.001000  0.900000    1.0   0.4518         50.0     0.010222\n",
    "        1  InProgress     1      0.037723      30  0.000062  0.843500    1.0   0.1202         50.0     0.010222\n",
    "        2  InProgress     1      0.000015      30  0.000865  0.821807    1.0   0.4121         50.0     0.010222\n",
    "        3  InProgress     1      0.298864      30  0.006991  0.942469    1.0   0.2283         49.0     0.010018\n",
    "        4  InProgress     0      0.000017      30  0.028001  0.911238      -        -            -            -\n",
    "        5  InProgress     0      0.000144      30  0.000080  0.870546      -        -            -            -\n",
    "6 trials running, 0 finished (0 until the end), 387.53s wallclock-time, 0.04068444444444444$ estimated cost\n",
    "```\n",
    "\n",
    "Since we specified `max_wallclock_time=3600` and `max_cost=20.0`, the tuning will stops when the wallclock time or estimated cost goes above the bound. In addition to providing a sense of the spending, the cost can also be optimized with our multiobjective optimizers, see this [link](https://github.com/awslabs/sagemaker-tune/blob/main/examples/launch_moasha_instance_tuning.py) for an example.\n",
    "\n",
    "Finally, we can plot the performance obtained in the same way as for the local case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_experiment = load_experiment(\"cifar10-2021-11-05-09-27-17-861\")\n",
    "tuning_experiment.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db538e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}